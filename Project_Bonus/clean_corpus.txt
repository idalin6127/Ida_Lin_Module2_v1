We gratefully a Search, ar Alv > cs > arXiv:2507.23776 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] Cascaded Information Disclosure for Generalized Evaluation of Problem Solving Capabilities Yunxiang Yan, Tomohiro Sawada, Kartik Goyal While question-answering~(QA) benchmark performance is an automatic and scalable method to compare LLMs, it is an indirect method of evaluating their underlying problem-solving capabilities. Therefore, we propose a holistic and generalizable framework based on \emph{cascaded question disclosure} that provides a more accurate estimate of the models’ problem-solving capabilities while maintaining the scalability and automation. This approach collects model responses in a stagewise manner with each stage revealing partial information about the question designed to elicit generalized reasoning in LLMs. We find that our approach not only provides a better comparison between LLMs, but also induces better intermediate traces in models compared to the standard QA paradigm. We empirically verify this behavior on diverse reasoning and knowledge-heavy QA datasets by comparing LLMs of varying sizes and families. Our approach narrows the performance gap observed in the standard QA evaluation settings, indicating that the prevalent indirect QA paradigm of evaluation overestimates the differences in performance between models. We further validate our findings by extensive ablation studies. ‘Comments: Under review Subjects: Computation and Language (cs.CL) Cite as: arXiv:2507.23776 [es.CL] (or arXiv:2507.23776v1 [es.CL] for this version) https://doi.org/10.48550/arXiv.2507.23776 @ Submission history From: Yunxiang Yan [view email] Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.23740 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs Nasim Shirvani-Mahdavi, Devin Wingfield, Amin Ghasemi, Chengkai Li Knowledge graphs (KGs) often contain sufficient information to support the inference of new facts. Identifying logical rules not only improves the completeness of a knowledge graph but also enables the detection of potential errors, reveals subtle data patterns, and enhances the overall capacity for reasoning and interpretation. However, the complexity of such rules, combined with the unique labeling conventions of each KG, can make them difficult for humans to understand. In this paper, we explore the potential of large language models to generate natural language explanations for logical rules. Specifically, we extract logical rules using the AMIE 3.5.1 rule discovery algorithm from the benchmark dataset FB15k-237 and two large-scale datasets, FB-CVT-REV and FB+CVT- REV. We examine various prompting strategies, including zero- and few-shot prompting, including variable entity types, and chain-of- thought reasoning. We conduct a comprehensive human evaluation of the generated explanations based on correctness, clarity, and hallucination, and also assess the use large language models as automatic judges. Our results demonstrate promising performance in terms of explanation correctness and clarity, although several challenges remain for future research. All scripts and data used in this study are publicly available at this https URLHthis https URL. Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs Al); Machine Learning (cs.LG) Cite as: arXiv:2507.23740 [es.CL] (or arXiv:2507.23740V1 [es.CL] for this version) https:/idoi.org/10.48550/arXiv.2507.23740 @ Submission history From: Nasim Shirvani-Mahdavi [view email] Access Paper: View PDF HTML (experimental) TeX Source Other Formats View lense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al cs.LG References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.23661 Help | Advanced Search All fields Computer Science > Computation and Language [Submitted on 31 Jul 2025] Arabic Hate Speech Identification and Masking in Social Media using Deep Learning Models and Pre-trained Models Fine-tuning Salam Thabet Doghmash, Motaz Saad Hate speech identification in social media has become an increasingly important issue in recent years. In this research, we address two problems: 1) to detect hate speech in Arabic text, 2) to clean a given text from hate speech. The meaning of cleaning here is replacing each bad word with stars based on the number of letters for each word. Regarding the first problem, we conduct several experiments using deep learning models and transformers to determine the best model in terms of the F1 score. Regarding second problem, we consider it as a machine translation task, where the input is a sentence containing dirty text and the output is the same sentence with masking the dirty text. The presented methods achieve best model in hate speech detection with a 92\% Macro F1 score and 95\% accuracy. Regarding the text cleaning experiment, the best result in the hate speech masking model reached 0.3 in BLEU score with 1-gram, which is a good result compared with the state of the art machine translation systems. Comments: 23 pages, 5 figures Subjects: Computation and Language (es.CL) ACM classes: 1.2.7 Cite as: arXiv:2507.23661 [es.CL] (or arXiv:2507.23661v1 [es.CL] for this version) https:/doi.org/10.48550/arxiv.2507.23661 @ Submission history From: Motaz Saad [view email] [v1] Thu, 31 Jul 2025 15:39:46 UTC (3,332 KB) Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.23588 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] DiffLoRA: Differential Low-Rank Adapters for Large Language Models Alexandre Misrahi, Nadezhda Chirkova, Maxime Louis, Vassilina Nikoulina Differential Transformer has recently been proposed to improve performance in Transformer models by canceling out noise through a denoiser attention mechanism. In this work, we introduce DiffLoRA, a parameter-efficient adaptation of the differential attention mechanism, with low-rank adapters on both positive and negative attention terms. This approach retains the efficiency of LORA while aiming to benefit from the performance gains of differential attention. We evaluate DiffLoRA across a broad range of NLP tasks, including general benchmarks, many-shot in-context learning, RAG, and long-context tests. We observe that, although DiffLoRA falls short of other parameter-efficient fine-tuning methods in most evaluation tasks, it shows interesting results in certain domains (+11 pts on LoRA for HumanEval). We analyze the attention patterns post-finetuning to identify the reasons for this behavior. ‘Subjects: Computation and Language (cs.CL) Cite as: arXiv:2507.23588 [es.CL] (or arXiv:2507.23588v1 [es.CL] for this version) https:/idoi.org/10.48550/arXiv.2507 23588 @ Submission history From: Alexandre Misrahi [view email] [v4] Thu, 31 Jul 2025 14:24:59 UTC (144 KB) Bibliographic Tools Code, Data, Media Demos Related Papers About arXivLabs Access Paper: View PDF HTML (experimental) TeX Source Other Formats View lense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark ed
We gratefully a Search, ar Alv > cs > arXiv:2507.23577 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] T-Detect: Tai of Adversarial Machine-Generated Text Alva West, Luodan Zhang, Liuliu Zhang, Minjun Zhu, Yixuan Weng, Yue Zhang The proliferation of sophisticated text generation models necessitates the development of robust detection methods capable of identifying machine-generated content, particularly text designed to evade detection through adversarial perturbations. Existing zero-shot detectors often rely on statistical measures that implicitly assume Gaussian distributions, a premise that falters when confronted with the heavy-tailed statistical artifacts characteristic of adversarial or non-native English texts. This paper introduces T-Detect, a novel detection method that fundamentally redesigns the statistical core of curvature-based detectors. Our primary innovation is the replacement of standard Gaussian normalization with a heavy-tailed discrepancy score derived from the Student's t-distribution. This approach is theoretically grounded in the empirical observation that adversarial texts exhibit significant leptokurtosis, rendering traditional statistical assumptions inadequate. T-Detect computes a detection score by normalizing the log-likelihood of a passage against the expected moments of a t-distribution, providing superior resilience to statistical outliers. We validate our approach on the challenging RAID benchmark for adversarial text and the comprehensive HART dataset. Experiments show that T-Detect provides a consistent performance uplift over strong baselines, improving AUROC by up to 3.9\% in targeted domains. When integrated into a two-dimensional detection framework (CT), our method achieves state-of the-art performance, with an AUROC of 0.926 on the Books domain of RAID. Our contributions are a new, theoretically-justified statistical foundation for text detection, an ablation-validated method that demonstrates superior robustness, and a comprehensive analysis of its performance under adversarial conditions. Ours code are released at this https URL. ‘Subjects: Computation and Language (cs.CL) Cite as: arXiv:2507.23577 Tes.CL] -Aware Statistical Normalization for Robust Detection Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by’ cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark AW
We gratefully a Search, ar Alv > cs > arXiv:2507.23541 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] Med-R“3: Enhancing Medical Retrieval-Augmented Reasoning of LLMs via Progressive Reinforcement Learning Keer Lu, Zheng Liang, Youquan Li, Jiejun Tan, Da Pan, Shusen Zhang, Guosheng Dong, Huang Leng In medical scenarios, effectively retrieving external knowledge and leveraging it for rigorous logical reasoning is of significant importance. Despite their potential, existing work has predominantly focused on enhancing either retrieval or reasoning capabilities of the models in isolation, with little attention given to their joint optimization, which leads to limited coordination between the two processes. Additionally, current methods rely heavily on supervised fine-tuning (SFT), which can cause models to memorize existing problem-solving pathways, thereby restricting their generalization ability when confronted with novel problem contexts. Furthermore, while some studies have explored to improve retrieval-augmented reasoning in general domains via reinforcement learning, their reward function designs do not adequately capture the specific demands of the medi these challenges, we introduce *Med-R"3", a **Med**ical **R“etrieval-augmented **R“easoning framework al domain. To address driven by progressive *R”einforcement learning. In this framework, we first develop the model's ability to perform logical reasoning over medical problems. Subsequently, on the basis of this foundation, we adaptively optimize the retrieval capability to better align with the characteristics of knowledge corpus and external information utilization throughout the reasoning process. Finally, we conduct joint optimization of the model's retrieval and reasoning coordination. Extensive experiments indicate that **Med-R"3** could achieve state-of- the-art performances, with LLaMA3.1-8B-Instruct + Med-R‘3 surpassing closed-sourced GPT-4o-mini by 3.931% at a comparable parameter scale, while Qwen2.5-14B augmented with Med-R’3 shows a more substantial gain of 13.53\%. ‘Subjects: Computation and Language (cs.CL) Cite as: arXiv:2507.23541 [es.CL] (or arXiv:2507.23541V1 [es.CL] for this version) Access Paper: View PDF TeX Source Other Formats view license Current browse context es.CL new | recent | 2025-07 Change to browse by: cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark AW
We gratefully a Search, ar Alv > cs > arXiv:2507.23486 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and Effectiveness in Clinical Domains Shirui Wang, Zhihui Tang, Huaxia Yang, Qiuhong Gong, Tiantian Gu, Hongyang Ma, Yongxin Wang, Wubin Sun, Zeliang Lian, Kehang Mao, Yinan Jiang, Zhicheng Huang, Lingyun Ma, Wenjie Shen, Yajie Ji, Yunhui Tan, Chunbo Wang, Yunlu Gao, Qianling Ye, Rui Lin, Mingyu Chen, Lijuan Niu, Zhihao Wang, Peng Yu, Mengran Lang, Yue Liu, Huimin Zhang, Haitao Shen, Long Chen, Qiguang Zhao, Si-Xuan Liu, Lina Zhou, Hua Gao, Dongqiang Ye, Lingmin Meng, Youtao Yu, Naixin Liang, Jianxiong Wu Large language models (LLMs) hold promise in clinical decision support but face major challenges in safety evaluation and effectiveness validation. We developed the Clinical Safety-Effectiveness Dual-Track Benchmark (CSEDB), a multidimensional framework built on clinical expert consensus, encompassing 30 criteria covering critical areas like critical illness recognition, guideline adherence, and medication safety, with weighted consequence measures. Thirty-two specialist physicians developed and reviewed 2,069 open-ended Q&A items aligned with these criteria, spanning 26 clinical departments to simulate real-world scenarios. Benchmark testing of six LLMs revealed moderate overall performance (average total score 57.2%, safety 54.7%, effectiveness 62.3%), with a significant 13.3% performance drop in high-risk scenarios (p new | recent | 2025-07 Change to browse by: cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark AW
We gratefully a Search, ar Alv > cs > arXiv:2507.23465 Help | Advanced Search All fields Computer Science > Computation and Language [Submitted on 31 Jul 2025] Role-Aware Language Models for Secure and Contextualized Access Control in Organizations Saeed Almheiri, Yerulan Kongrat, Adrian Santosh, Ruslan Tasmukhanov, Josemaria Vera, Muhammad Dehan Al Kautsar, Fajri Koto As large language models (LLMs) are increasingly deployed in enterprise settings, controlling model behavior based on user roles becomes an essential requirement. Existing safety methods typically assume uniform access and focus on preventing harmful or toxic outputs, without addressing role-specific access constraints. In this work, we investigate whether LLMs can be fine-tuned to generate responses that reflect the access privileges associated with different organizational roles. We explore three modeling strategies: a BERT-based classifier, an LLM-based classifier, and role-conditioned generation. To evaluate these approaches, we construct two complementary datasets. The first is adapted from existing instruction-tuning corpora through clustering and role labeling, while the second is synthetically generated to reflect realistic, role-sensitive enterprise scenarios. We assess model performance across varying organizational structures and analyze robustness to prompt injection, role mismatch, and jailbreak attempts. ‘Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.Al) Cite as: arXiv:2507.23465 [es.CL] (or arXiv:2507.23465v1 [es.CL] for this version) https:/idoi.org/10.48550/arXiv.2507.23465 @ Submission history From: Saeed Almheiri [view email] [v4] Thu, 31 Jul 2025 11:41:04 UTC (2,381 KB) Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, All fields Help | Advanced Search Computer Science > Computation and Language Access Paper: [Submitted on 31 Jul 2025] View PDF Beyond Passive Critical Thinking: Fostering Proactive ATM (experimental) e, Ource Questioning to Enhance Human-Al Collaboration Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs Ante Wang, Yujie Lin, Jingyao Liu, Suhang Wu, Hao Liu, Xinyan Xiao, Jinsong Su Critical thinking is essential for building robust Al systems, preventing them from blindly accepting flawed data or biased reasoning. However, prior work has primarily focused on passive critical thinking, where models simply reject problematic queries without taking constructive steps to address user requests. In this work, we introduce proactive critical thinking, a paradigm where models actively seek missing or clarifying information from users to resolve their queries better. To evaluate this capability, we present GSM-MC and GSM-MCE, two novel benchmarks based on GSMSK for assessing mathematical reasoning under incomplete or misleading conditions. References & Citations GSM-MC contains 1,368 math problems with a key variable deliberately removed, requiring models to identify NASAADS and request the missing information. GSM-MCE further increases the difficulty by introducing irrelevant details to Soe Se an test robustness against distractions. Experiments on Qwen3 and Llama series models show that, while these a‘ ‘ i Export BibTeX Citation models excel in traditional reasoning tasks due to extensive post-training and inference-time scaling, they struggle with proactive critical thinking, especially smaller ones. However, we demonstrate that reinforcement Bookmark learning (RL) can significantly improve this ability. Using our enhanced RL algorithm, we achieve substantial £8 gains, boosting the Qwen3-1.7B's accuracy from 0.15% to 73.98% on GSM-MC. We hope this work advances models that collaborate more effectively with users in problem-solving through proactive critical thinking. ‘Subjects: Computation and Language (cs.CL) Cite as: arXiv:2507.23407 [es.CL] (or arXiv:2507.23407V1 [es.CL] for this version) https:/idoi.org/10.48550/arXiv.2507.23407 @ Submission history
We gratefully a Search, All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] Enhanced Arabic Text Retrieval with Attentive Relevance Scoring Salah Eddine Bekhouche, Azeddine Benlamoudi, Yazid Bounab, Fadi Dornaika, Abdenour Hadid Arabic poses a particular challenge for natural language processing (NLP) and information retrieval (IR) due to its complex morphology, optional diacritics and the coexistence of Modern Standard Arabic (MSA) and various dialects. Despite the growing global significance of Arabic, it is still underrepresented in NLP research and benchmark resources. In this paper, we present an enhanced Dense Passage Retrieval (DPR) framework developed specifically for Arabic. At the core of our approach is a novel Attentive Relevance Scoring (ARS) that replaces standard interaction mechanisms with an adaptive scoring function that more effectively models the semantic relevance between questions and passages. Our method integrates pre-trained Arabic language models and architectural refinements to improve retrieval performance and significantly increase ranking accuracy when answering Arabic questions. The code is made publicly available at \hreffthis https URL}{GitHub}. ‘Subjects: Computation and Language (cs.CL) Cite as: arXiv:2507.23404 [es.CL] (or arXiv:2507.23404v1 [es.CL] for this version) https:/idoi.org/10.48550/arXiv.2507.23404 @ Submission history From: Salah Eddine Bekhouche SE. Bekhouche [view email] [v1] Thu, 31 Jul 2025 10:18:28 UTC (166 KB) Bibliographic Tools Code, Data, Media Demos Related Papers About arXivLabs Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark AH
We gratefully a Search, All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] MRGSEM-Sum: An Unsupervised Multi-document Summarization Framework based on Multi-Relational Graphs and Structural Entropy Minimization Yongbing Zhang, Fang Nan, Shengxiang Gao, Yuxin Huang, Kaiwen Tan, Zhengtao Yu The core challenge faced by multi-document summarization is the complexity of relationships among documents and the presence of information redundancy. Graph clustering is an effective paradigm for addressing this issue, as it models the complex relationships among documents using graph structures and reduces information redundancy through clustering, achieving significant research progress. However, existing methods often only consider single-relational graphs and require a predefined number of clusters, which hinders their ability to fully represent rich relational information and adaptively partition sentence groups to reduce redundancy. To overcome these limitations, we propose MRGSEM-Sum, an unsupervised multi-document summarization framework based ‘on multi-relational graphs and structural entropy minimization. Specifically, we construct a multi-relational graph that integrates semantic and discourse relations between sentences, comprehensively modeling the intricate and dynamic connections among sentences across documents. We then apply a two-dimensional structural entropy minimization algorithm for clustering, automatically determining the optimal number of clusters and effectively organizing sentences into coherent groups. Finally, we introduce a position-aware compression mechanism to distill each cluster, generating concise and informative summaries. Extensive experiments on four benchmark datasets (Multi-News, DUC-2004, PubMed, and WikiSum) demonstrate that our approach consistently outperforms previous unsupervised methods and, in several cases, achieves performance comparable to supervised models and large language models. Human evaluation demonstrates that the summaries generated by MRGSEM-Sum exhibit high consistency and coverage, approaching human-level quality. ‘Subjects: Computation and Language (¢s.CL); Information Retrieval (cs.IR) Access Paper: View PDF HTML (experimental) TeX Source Other Formats COE) view tcense Current browse context: cs.CL new | recent | 2025-07 Change to browse by: cs cs.IR References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark AW
We gratefully a Search, ar Alv > cs > arXiv:2507.23399 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] Beyond the Cloud: Assessing the Benefits and Drawbacks of Local LLM Deployment for Translators Peter Sandrini The rapid proliferation of Large Language Models presents both opportunities and challenges for the translation field. While commercial, cloud-based Al chatbots have garnered significant attention in translation studies, concems regarding data privacy, security, and equitable access necessitate exploration of alternative deployment models. This paper investigates the feasibility and performance of locally deployable, free language models as a viable alternative to proprietary, cloud-based Al solutions. This study evaluates three open-source models installed on CPU-based platforms and compared against commercially available online chat-bots. The evaluation focuses on functional performance rather than a comparative analysis of human-machine translation quality, an area already subject to extensive research. The platforms assessed were chosen for their accessibility and ease of use across various operating systems. While local deployment introduces its own challenges, the benefits of enhanced data control, improved privacy, and reduced dependency on cloud services are compelling. The findings of this study contribute to a growing body of knowledge conceming the democratization of Al technology and inform future research and development efforts aimed at making LLMs more accessible and practical for a wider range of users, specifically focusing on the needs of individual translators and small businesses. Subjects: Computation and Language (es.CL); Computers and Society (cs.CY) ACM classes: 1.2.7; K.4.3 Cite as: arXiv:2507.23399 [es.CL] (or arXiv:2507.23399V1 [es.CL] for this version) https://doi.org/10.48550/arXiv.2507.23399 @ Submission history Access Paper: View PDF Other Formats (ERE) view ticense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs.CY References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.23386 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models Ailiang Lin, Zhuoyun Li, Kotaro Funakoshi Decoder-only large language models (LLMs) are increasingly used to build embedding models that effectively encode the semantic information of natural language texts into dense vector representations for various embedding tasks. However, many existing methods primarily focus on removing the causal attention mask in LLMs to enable bidirectional attention, potentially undermining the mode''s ability to extract semantic information acquired during pretraining. Additionally, leading unidirectional approaches often rely on extra input text to ‘overcome the inherent limitations of causal attention, inevitably increasing computational costs. In this work, we propose Causal2Vec, a general-purpose embedding model tailored to enhance the performance of decoder-only LLMs without altering their original architectures or introducing significant computational overhead. Specifically, we first employ a lightweight BERT-style model to pre-encode the input text into a single Contextual token, which is then prepended to the LLM's input sequence, allowing each token to capture contextualized information even without attending to future tokens. Furthermore, to mitigate the recency bias introduced by last-token pooling and help LLMs better leverage the semantic information encoded in the Contextual token, we concatenate the last hidden states of Contextual and EOS tokens as the final text embedding. In practice, Causal2Vec achieves state- of-the-art performance on the Massive Text Embeddings Benchmark (MTEB) among models trained solely on publicly available retrieval datasets, while reducing the required sequence length by up to 85% and inference time by up to 82% compared to best-performing methods. ‘Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.Al) Cite as: arXiv:2507.23386 [es.CL] (or arXiv:2507.23386v1 [es.CL] for this version) https://doi.org/10.48550/arXiv.2507 23386 @ Access Paper: View PDF HTML (experimental) TeX Source Other Formats View lense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.23382 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models Yiyan Ji, Haoran Chen, Qiguang Chen, Chengyue Wu, Libo Qin, Wanxiang Che Multimodal planning capabilities refer to the ability to predict, reason, and design steps for task execution with multimodal context, which is essential for complex reasoning and decision-making across multiple steps. However, current benchmarks face two key challenges: (1) they cannot directly assess multimodal real-world planning capabilities, and (2) they lack constraints or implicit constraints across modalities. To address these issues, we introduce with Complex Constraints (MPCC), the first benchmark to systematically evaluate MLLMs' ability to handle multimodal constraints in planning. To address the first challenge, MPCC focuses on three real-world tasks: Flight Planning, Calendar Planning, and Meeting Planning. To solve the second challenge, we introduce complex constraints (e.g. budget, temporal, and spatial) in these tasks, with graded difficulty levels (EASY, MEDIUM, HARD) to separate constraint complexity from search space expansion. Experiments on 13 advanced MLLMs reveal significant challenges: closed-source models achieve only 21.3% feasible plans, while open-source models average below 11%. Additionally, we observe that MLLMs are highly sensitive to constraint complexity and that traditional multimodal prompting strategies fail in multi- constraint scenarios. Our work formalizes multimodal constraints in planning, provides a rigorous evaluation framework, and highlights the need for advancements in constraint-aware reasoning for real-world MLLM applications. Comments: Accepted to ACM Multimedia 2025 Subjects: Computation and Language (es.CL); Artificial Intelligence (cs.Al); Computer Vision and Pattern Recognition (cs.CV) AGM classes: 2.2.8; 1.2.10 Cite as: arXiv:2507.23382 [es.CL] (or arXiv:2507.23382V1 [es.CL] for this version) Access Paper: View PDF HTML (experimental) TeX Source Other Formats REE view ticense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al cs.CV References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark AW
We gratefully a ar Alv > cs > arXiv:2507.23358 Search, All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] Text-to-SQL Task-oriented Dialogue Ontology Construction Renato Vukovic, Carel van Niekerk, Michael Heck, Benjamin Ruppik, Hsien-Chin Lin, Shutong Feng, Nurul Lubis, Milica Gasic Large language models (LLMs) are widely used as general-purpose knowledge sources, but they rely on parametric knowledge, limiting explainability and trustworthiness. In task-oriented dialogue (TOD) systems, this separation is explicit, using an external database structured by an explicit ontology to ensure explainability and controllability. However, building such ontologies requires manual labels or supervised training. We introduce TeQoDO: a Text-to-SQL task-oriented Dialogue Ontology construction method. Here, an LLM autonomously builds a TOD ontology from scratch without supervision using its inherent SQL programming capabilities combined with dialogue theory provided in the prompt. We show that TeQoDO outperforms transfer learning approaches, and its constructed ontology is competitive on a downstream dialogue state tracking task. Ablation studies demonstrate the key role of dialogue theory. TeQoDO also scales to allow construction of much larger ontologies, which we investigate on a Wikipedia and ArXiv dataset. We view this as a step towards broader application of ontologies to increase LLM explainability. Subjects: Computation and Language (¢s.CL); Artificial Intelligence (cs.Al); Databases (cs.DB); Information Retrieval (cs.IR) Cite as: arXiv:2507.23358 [es.CL] (or arXiv:2507.23358v1 [es.CL] for this version) https:/doi.org/10.48550/arXiv.2507 23358 @ Submission history From: Renato Vukovic [view email] [v4] Thu, 31 Jul 2025 09:08:59 UTC (274 KB) Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al cs.DB csIR References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, All fields ar Alv > cs > arXiv:2507.23334 Help | Advanced Search Computer Science > Computation and Language Access Paper: [Submitted on 31 Jul 2025] View PDF MUST-RAG: MUSical Text Question Answering with Retrieval HTML (experimental) Augmented Generation Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs Daeyong Kwon, SeungHeon Doh, Juhan Nam Recent advancements in Large language models (LLMs) have demonstrated remarkable capabilities across diverse domains. While they exhibit strong zero-shot performance on various tasks, LLMs’ effectiveness in music-related applications remains limited due to the relatively small proportion of music-specific knowledge in their training data. To address this limitation, we propose MusT-RAG, a comprehensive framework based on Retrieval Augmented Generation (RAG) to adapt general-purpose LLMs for text-only music question answering cs.Al (MQA) tasks. RAG is a technique that provides external knowledge to LLMs by retrieving relevant context S RR information when generating answers to questions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a music-specialized vector database for the retrieval stage, and (2) utilizes context information References & Citations during both inference and fine-tuning processes to effectively transform general-purpose LLMs into music- NASAADS Google Scholar specific models. Our experiment demonstrates that MusT-RAG significantly outperforms traditional fine-tuning Son ee an approaches in enhancing LLMs’ music domain adaptation capabilities, showing consistent improvements across both in-domain and out-of-domain MQA benchmarks. Additionally, our MusWikiDB proves substantially more Export BibTeX Citation effective than general Wikipedia corpora, delivering superior performance and computational efficiency, Bookmark ‘Comments: 8 pages, 2 figures Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.Al); Information Retrieval (cs.IR); Machine Learning (cs.LG) Cite as: arXiv:2507.23334 [es.CL] (or arXiv:2507.23334V1 [es.CL] for this version) https://doi.org/10.48550/arXiv.2507 23334 @ Submission history
We gratefully a Search, All fields ar Alv > cs > arXiv:2507.23319 Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] What's Taboo for You? - An Empirical Evaluation of LLMs Behavior Toward Sensitive Content Alfio Ferrara, Sergio Picascia, Laura Pinnavaia, Vojimir Ranitovic, Elisabetta Rocchetti, Alice Tuveri Proprietary Large Language Models (LLMs) have shown tendencies toward politeness, formality, and implicit content moderation. While previous research has primarily focused on explicitly training models to moderate and detoxify sensitive content, there has been limited exploration of whether LLMs implicitly sanitize language without explicit instructions. This study empirically analyzes the implicit moderation behavior of GPT-4o-mini when paraphrasing sensitive content and evaluates the extent of sensitivity shifts. Our experiments indicate that GPT- 4o-mini systematically moderates content toward less sensitive classes, with substantial reductions in derogatory and taboo language. Also, we evaluate the zero-shot capabilities of LLMs in classifying sentence sensitivity, comparing their performances against traditional methods. ‘Subjects: Computation and Language (cs.CL) Cite as: arXiv:2507.23319 fes.CL] (or arXiv:2507.23319V1 [es.CL] for this version) https:/idoi.org/10.48550/arXiv.2507.23319 @ Submission history From: Sergio Picascia [view email] [v1] Thu, 31 Jul 2025 08:02:04 UTC (761 KB) Bibliographic Tools Code, Data, Media Demos Related Papers About arXivLabs Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark ed
We gratefully a Search, ar Alv > cs > arXiv:2507.23279 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] Unveiling Super Experts in Mixture-of-Experts Large Language Models Zunhai Su, Qingyuan Li, Hao Zhang, YuLei Qian, Yuchen Xie, Kehong Yuan Sparsely activated Mixture-of Experts (MoE) models have shown promise in enhancing the learning capacity of large language models (LLMs). Leveraging the intrinsic importance differences among experts, recent research has explored expert-level compression techniques to improve the efficiency of MoE LLMs. However, existing approaches often rely on empirical criteria to identify critical experts, lacking a deeper exploration and understanding of the heterogeneous importance of experts. In this study, we present the first discovery and investigation of a distinct subset of experts that play a crucial role in the underlying mechanisms during the model's forward inference. These experts are prevalent in open-source MoE LLMs, and despite their limited number, pruning them leads to a significant decline in model performance (e.g., pruning three causes Qwen3- 30B-A3B to produce repetitive and uninformative outputs). We refer to these experts as Super Experts (SEs) Our comprehensive analysis provides progressively deeper insights into SEs. (i) SEs are characterized by rare but extreme activation outliers in the output of the down_proj, which give rise to massive activations in the hidden states between decoder layers. Moreover, the distribution of SEs remains model-specific and is unaffected by post-training processes. (ii) By pruning SEs, we assess their significance across a variety of tasks, revealing their considerable impact on the mode's overall performance, particularly in mathematical reasoning. (iii) We further enhance our understanding of the influence of SEs compression. Our findings confirm that MoE LLMs rely on SEs to induce attention sinks, which are crucial for the distribution of attention scores but are significantly disrupted by SE pruning. The code is available at this https URL. ‘Subjects: Computation and Language (cs.CL) Cite as: arXiv:2507.23279 fes.CL] (or arXiv:2507.23279V1 [es.CL] for this version) Access Paper: View PDF HTML (experimental) TeX Source Other Formats View lense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > es > arXiv:2507.23248 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] Evaluating LLMs’ Multilingual Capabilities for Bengali: Benchmark Creation and Performance Analysis Shimanto Bhowmik, Tawsif Tashwar Dipto, Md Sazzad Islam, Sheryl Hsu, Tahsin Reasat Bengali is an underrepresented language in NLP research. However, it remains a challenge due to its unique linguistic structure and computational constraints. In this work, we systematically investigate the challenges that hinder Bengali NLP performance by focusing on the absence of standardized evaluation benchmarks. We then evaluated 10 recent open source Large Language Models (LLMs) in 8 of the translated datasets and performed a comprehensive error analysis to pinpoint their primary failure modes. Our findings reveal consistent performance gaps for Bengali compared to English, particularly for smaller models and specific model families like Mistral. We also identified promising robustness in certain architectures, such as DeepSeek, that maintain more stable performance across languages. Our analysis reveals an inverse relationship between tokenization efficiency and LLM accuracy where models tend to perform worse when inputs are excessively tokenized, whereas more efficient \& concise tokenization results in improved performance. These findings highlight critical areas where current models fall short and underscore the need for improved dataset quality and evaluation methodologies tailored to multilingual contexts. This work will catalyze further research on NLP for underrepresented languages, helping to democratize access to advanced language technologies worldwide. The code and dataset used in this research is publicly available at this https URL. ‘Subjects: Computation and Language (es.CL); Machine Learning (cs.LG) Cite as: arXiv:2507.23248 [es.CL] (or arXiv:2507.23248v1 [es.CL] for this version) https:/idoi.org/10.48550/arXiv.2507 23248 @ Submission history Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs.LG References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.23247 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] P-ReMIS: Pragmatic Reasoning in Mental Health and a Social Implication Sneha Oram, Pushpak Bhattacharyya There has been an increase in recent advancements in the explainability and development of personalized chatbots for mental health. However, the reasoning aspects for explainability and dialogue discourse have not been explored previously for mental health. Hence, we are investigating the pragmatic reasoning capability of large language models (LLMs) in this domain. We introduce P-ReMe dataset, and propose a modified definition for the pragmatic phenomena of implicature (implied meaning) and presupposition (implicit assumption) in mental health. Following the definition, we formulate two tasks in implicature and one task in presupposition. To benchmark the dataset and the presented tasks, we consider four models - Llama3.1, Mistral, MentaLLaMa, and ‘Qwen. The results of the experiments suggest that Mistral and Qwen show substantial reasoning capabilities in the domain. In addition, we also propose StiPRompts to study the stigma around mental health with the state-of- the-art LLMs, GPT-4o mini, Deepseek-chat, and Claude-3.5-haiku. Our evaluated findings show that Claude-3.5- haiku deals with the stigma more responsibly compared to the other two LLMs. ‘Subjects: Computation and Language (cs.CL) Cite as: arXiv:2507.23247 [es.CL] (or arXiv:2507.23247v1 [es.CL] for this version) https:/idoi.org/10.48550/arXiv.2507.23247 @ Submission history From: Sneha Oram [view email] [v4] Thu, 31 Jul 2025 05:10:38 UTC (7,303 KB) Access Paper: View PDF HTML (experimental) TeX Source Other Formats View lense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.23227 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs Sophie Kearney, Shu Yang, Zixuan Wen, Bojian Hou, Duy Duong-Tran, Tianlong Chen, Jason Moore, Marylyn Ritchie, Li Shen Early and accurate diagnosis of Alzheimer's disease (AD), a complex neurodegenerative disorder, requires analysis of heterogeneous biomarkers (e.g., neuroimaging, genetic risk factors, cognitive tests, and cerebrospinal fluid proteins) typically represented in a tabular format. With flexible few-shot reasoning, multimodal integration, and natural language-based interpretability, large language models (LLMs) offer unprecedented opportunities for prediction with structured biomedical data. We propose a novel framework called TAP-GPT, Tabular Alzheimer's Prediction GPT, that adapts TableGPT2, a multimodal tabular-specialized LLM originally developed for business intelligence tasks, for AD diagnosis using structured biomarker data with small sample sizes. Our approach constructs few-shot tabular prompts using in-context learning examples from structured biomedical data and finetunes TableGPT2 using the parameter-efficient qLoRA adaption for a clinical binary classification task of AD or cognitively normal (CN). The TAP-GPT framework harnesses the powerful tabular understanding ability of TableGPT2 and the encoded prior knowledge of LLMs to outperform more advanced general-purpose LLMs and a tabular foundation model (TFM) developed for prediction tasks. To our knowledge, this is the first application of LLMs to the prediction task using tabular biomarker data, paving the way for future LLM-driven multi-agent frameworks in biomedical informatics. ‘Subjects: Computation and Language (¢s.CL); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM) Cite as: arXiv:2507.23227 fes.CL] (or arXiv:2507.23227V1 [es.CL] for this version) https:/idoi.org/10.48550/arXiv.2507.23227 @ Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.23220 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] Model Directions, Not Words: Mechanistic Topic Models Using Sparse Autoencoders Carolina Zheng, Nicolas Beltran-Velez, Sweta Karlekar, Claudia Shi, Achille Nazaret, Asif Mallik, Amir Feder, David M. Blei Traditional topic models are effective at uncovering latent themes in large text collections. However, due to their reliance on bag-of-words representations, they struggle to capture semantically abstract features. While some neural variants use richer representations, they are similarly constrained by expressing topics as word lists, which limits their ability to articulate complex topics. We introduce Mechanistic Topic Models (MTMs), a class of topic models that operate on interpretable features learned by sparse autoencoders (SAEs). By defining topics over this semantically rich space, MTMs can reveal deeper conceptual themes with expressive feature descriptions. Moreover, uniquely among topic models, MTMs enable controllable text generation using topic- based steering vectors. To properly evaluate MTM topics against word-list-based approaches, we propose \textit{topic judge}, an LLM-based pairwise comparison evaluation framework. Across five datasets, MTMs match or exceed traditional and neural baselines on coherence metrics, are consistently preferred by topic judge, and enable effective steering of LLM outputs. ‘Subjects: Computation and Language (es.CL); Machine Learning (cs.LG) Cite as: arXiv:2507.23220 fes.CL] (or arXiv:2507.23220V1 [es.CL] for this version) https:/idoi.org/10.48550/arXiv.2507.23220 @ Submission history From: Carolina Zheng [view email] [v4] Thu, 31 Jul 2025 03:17:43 UTC (2,524 KB) Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs.LG References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.23211 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] Failures Are the Stepping Stones to Success: Enhancing Few-Shot In-Context Learning by Leveraging Negative Samples Yunhao Liang, Ruixuan Ying, Takuya Taniguchi, Zhe Cui Large Language Models exhibit powerful few-shot in-context learning (ICL) capabilities, but the performance is highly sensitive to provided examples. Recent research has focused on retrieving corresponding examples for each input query, not only enhancing the efficiency and scalability of the leaming process but also mitigating inherent biases in manual example selection. However, these studies have primarily emphasized leveraging Positive samples while overlooking the additional information within Negative samples for contextual learning. We propose a novel method that utilizes Negative samples to better select Positive sample examples, thereby enhancing the performance of few-shot ICL. Initially, we construct Positive and Negative sample corpora based on Zero-Shot-Cot. Then, during inference, we employ a semantic similarity-based approach to select the most similar examples from both the Positive and Negative corpora for a given query. Subsequently, we further retrieve Positive examples from the Positive sample corpus based on semantic similarity to the Negative examples, then concatenating them with the previously selected Positive examples to serve as ICL demonstrations. Experimental results demonstrate that our approach surpasses methods solely relying on the most similar positive examples for context, validating that the additional information in negative samples aids in enhancing ICL performance through improved Positive sample selection. ‘Subjects: Computation and Language (cs.CL) Cite as: arXiv:2507.23211 [es.CL] (or arXiv:2507.23211V1 [es.CL] for this version) https://doi.org/10.48550/arXiv.2507.23211 @ Access Paper: View PDF HTML (experimental) TeX Source Other Formats View lense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.23194 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] Geak: Introducing Triton Kernel Al Agent & Evaluation Benchmarks Jianghui Wang, Vinay Joshi, Saptarshi Majumder, Xu Chao, Bin Ding, Zigiong Liu, Pratik Prabhanjan Brahma, Dong Li, Zicheng Liu, Emad Barsoum The demand for Al-generated GPU kernels is rapidly growing, influenced by the need for scalable, hardware- optimized solutions in both industry and academia. As deep learning workloads grow in complexity and diversity, it is imperative to automate low-level kernel development to meet performance and productivity demands. Major cloud providers, semiconductor companies, and research institutions are now investing heavily in Al-driven code generation for GPUs, aiming to reduce manual optimization efforts while achieving near-expert performance on hardware like AMD MI300X. The Triton language, a Python-based DSL for GPU programming, has emerged as a popular target for such Al-generated kernels due to its balance of performance and ease-of-coding. In this work, we present an evaluation suite for Triton-based GPU kernels and GEAK (Generating Efficient Al-centric GPU Kernels)-a framework that leverages cutting-edge LLMs to generate performant Triton code specifically for AMD GPUs, including the AMD MI300X and MI250. GEAK leverages inference-time compute scaling to produce Triton-based GPU kernels using a reasoning loop adapted from Reflexion-style feedback mechanisms. On two evaluation benchmarks, GEAK significantly outperformed the baselines of directly prompting frontier LLMs as well as Reflexion-based generation pipelines by achieving correctness up to 63% and execution speed up of up to 2.59X. These results highlight the promise of GEAK-like agentic code generation for accelerating the adoption of diverse hardware platforms and democratizing access to expert-level kemel performance. Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs Al); Machine Learning (cs.LG) Cite as: arXiv:2507.23194 [es.CL] (or arXiv:2507.23194v1 [es.CL] for this version) httos://doi ora/10.48550/arXiv.2507 23194 @ Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al cs.LG References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, All fields ar Alv > cs > arXiv:2507.23167 Help | Advanced Search Computer Science > Computation and Language [Submitted on 31 Jul 2025] LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration Jizhou Guo Large Language Models (LLMs) have demonstrated impressive performance across various tasks, with different models excelling in distinct domains and specific abilities. Effectively combining the predictions of multiple LLMs is crucial for enhancing system robustness and performance. However, existing ensemble methods often rely on simple techniques like voting or logits ensembling, which overlook the varying confidence and reliability of models in different contexts. In this work, we propose LENS (Learning ENsemble confidence from Neural States), a novel approach that leas to estimate model confidence by analyzing internal representations. For each LLM, we train a lightweight linear confidence predictor that leverages layer-wise hidden states and normalized probabilities as inputs. This allows for more nuanced weighting of model predictions based on their context- dependent reliability. Our method does not require modifying the model parameters and requires negligible additional computation. Experimental results on multiple-choice and boolean question-answering tasks demonstrate that LENS outperforms traditional ensemble methods by a substantial margin. Our findings suggest that internal representations provide valuable signals for determining model confidence and can be effectively leveraged for ensemble learning. ‘Subjects: Computation and Language (¢s.CL); Artificial Intelligence (cs.Al); Machine Learning (cs.LG); Multiagent Systems (cs.MA) Cite as: arXiv:2507.23167 [es.CL] (or arXiv:2507.23167V1 [es.CL] for this version) hitps://doi.org/10.48550/arXiv.2507.23167 @ Submission history From: Jizhou Guo [view email] Access Paper: View PDF HTML (experimental) TeX Source Other Formats View lense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al cs. LG cs.MA References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.23158 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 30 Jul 2025) User Feedback in Human-LLM Dialogues: A Lens to Understand Users But Noisy as a Learning Signal Yuhan Liu, Michael J.Q. Zhang, Eunsol Choi Once language models (LMs) are deployed, they can interact with users long-term, ideally evolving continuously based on their feedback. Asking for direct user feedback can be disruptive; thus, we study harvesting user feedback from user-LM interaction logs. We study implicit user feedback in two user-LM interaction datasets (WildChat and LMSYS). First, we analyze user feedback in the user-LLM conversation trajectory, providing insights into when and why such feedback occurs. Second, we study harvesting learning signals from such implicit user feedback. We find that the contents of user feedback (e.g., user wanted clarification), not just the polarity (e.g., users were unhappy with the previous model response), can improve model performance in short human-designed questions (MTBench) but not on longer and more complex questions (WildBench). We also find that the usefulness of user feedback is largely tied to the quality of the user's initial prompt. Together, we provide an in-depth study of implicit user feedback, showing its potential and limitations. Comments: Earlier version of this paper was presented at 2nd Workshop on Models of Human Feedback for Al Alignment (MoFA), ICML 2025 Subjects: Computation and Language (cs.CL) Cite as: arXiv:2507.23158 [es.CL] (or arXiv:2507.23158v1 [es.CL] for this version) https://doi.org/10.48550/arXiv.2507.23158 @ Submission history From: Yuhan Liu [view email] [v1] Wed, 30 Jul 2025 23:33:29 UTC (528 KB) Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, All fields ar Alv > cs > arXiv:2507.23135 Help | Advanced Search Computer Science > Computation and Language [Submitted on 30 Jul 2025] ISO-Bench: Benchmarking Multimodal Causal Reasoning in Visual-Language Models through Procedural Plans Ananya Sadana, Yash Kumar Lal, Jiawei Zhou Understanding causal relationships across modalities is a core challenge for multimodal models operating in real- world environments. We introduce ISO-Bench, a benchmark for evaluating whether models can infer causal dependencies between visual observations and procedural text. Each example presents an image of a task step and a text snippet from a plan, with the goal of deciding whether the visual step occurs before or after the referenced text step. Evaluation results on ten frontier vision-language models show underwhelming performance: the best zero-shot F1 is only 0.57, and chain-of-thought reasoning yields only modest gains (up to 0.62 F1), largely behind humans (0.98 F1). Our analysis further highlights concrete directions for improving causal understanding in multimodal models. ‘Subjects: Computation and Language (cs.CL) Cite as: arXiv:2507.23135 [es.CL] (or arXiv:2507.23135v1 [es.CL] for this version) https://doi.org/10.48550/arXiv.2507.23135 @ Submission history From: Yash Kumar Lal [view email] [v1] Wed, 30 Jul 2025 22:30:48 UTC (1,290 KB) Bibliographic Tools Code, Data, Media Demos Related Papers About arXivLabs Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > es > arXiv:2507.23121 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 30 Jul 2025] Uncovering the Fragility of Trustworthy LLMs through Chinese Textual Ambiguity Xinwei Wu, Haojie Li, Hongyu Liu, Xinyu Ji, Ruohan Li, Yule Chen, Yigeng Zhang In this work, we study a critical research problem regarding the trustworthiness of large language models (LLMs): how LLMs behave when encountering ambiguous narrative text, with a particular focus on Chinese textual ambiguity. We created a benchmark dataset by collecting and generating ambiguous sentences with context and their corresponding disambiguated pairs, representing multiple possible interpretations. These annotated examples are systematically categorized into 3 main categories and 9 subcategories. Through experiments, we discovered significant fragility in LLMs when handling ambiguity, revealing behavior that differs substantially from humans. Specifically, LLMs cannot reliably distinguish ambiguous text from unambiguous text, show overconfidence in interpreting ambiguous text as having a single meaning rather than multiple meanings, and exhibit overthinking when attempting to understand the various possible meanings. Our findings highlight a fundamental limitation in current LLMs that has significant implications for their deployment in real-world applications where linguistic ambiguity is common, calling for improved approaches to handle uncertainty in language understanding. The dataset and code are publicly available at this GitHub repository: this https URL. ‘Comments: Accepted at KDD workshop on Evaluation and Trustworthiness of Agentic and Generative Al Models (Agentic & GenAl Evaluation Workshop KDD '25) ‘Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.All) Cite as: arXiv:2507.23121 [es.CL] (or arXiv:2507.23121V1 [es.CL] for this version) https://doi.org/10.48550/arXiv.2507.23121 @ Submission history Access Paper: View PDF HTML (experimental) TeX Source Other Formats View lense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.23104 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 30 Jul 2025) RASL: Retrieval Augmented Schema Linking for Massive Database Text-to-SQL Jeffrey Eben, Aitzaz Ahmad, Stephen Lau Despite advances in large language model (LLM)-based natural language interfaces for databases, scaling to enterprise-level data catalogs remains an under-explored challenge. Prior works addressing this challenge rely ‘on domain-specific fine-tuning - complicating deployment - and fail to leverage important semantic context contained within database metadata. To address these limitations, we introduce a component-based retrieval architecture that decomposes database schemas and metadata into discrete semantic units, each separately indexed for targeted retrieval. Our approach prioritizes effective table identification while leveraging column-level information, ensuring the total number of retrieved tables remains within a manageable context budget. Experiments demonstrate that our method maintains high recall and accuracy, with our system outperforming baselines over massive databases with varying structure and available metadata. Our solution enables practical text-to-SQL systems deployable across diverse enterprise settings without specialized fine-tuning, addressing a critical scalability gap in natural language database interfaces. Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs Al); Machine Learning (cs.LG) Cite as: arXiv:2507.23104 [es.CL] (or arXiv:2507.23104v1 [es.CL] for this version) https:/doi.org/10.48550/arXiv.2507.23104 @ Submission history From: Jeff Eben [view email] [v1] Wed, 30 Jul 2025 21:09:47 UTC (554 KB) Access Paper: View PDF TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al cs.LG References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.23095 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 30 Jul 2025) SMART-Editor: A Mul Editing with Structural Integrity Ishani Mondal, Meera Bharadwaj, Ayush Roy, Aparna Garimella, Jordan Lee Boyd-Graber We present SMART-Editor, a framework for compositional layout and content editing across structured (posters, websites) and unstructured (natural images) domains. Unlike prior models that perform local edits, SMART-Editor preserves global coherence through two strategies: Reward-Refine, an inference-time rewardguided refinement method, and RewardDPO, a training-time preference optimization approach using reward-aligned layout pairs. To evaluate model performance, we introduce SMARTEdit-Bench, a benchmark covering multi-domain, cascading edit scenarios. SMART-Editor outperforms strong baselines like InstructPix2Pix and HIVE, with RewardDPO. achieving up to 15% gains in structured settings and Reward-Refine showing advantages on natural images. Automatic and human evaluations confirm the value of reward-guided planning in producing semantically consistent and visually aligned edits. ‘Comments: Under Submission ‘Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.All) Cite as: _arXiv:2507.23095 [es.CL] (or arXiv:2507.23095v1 [es.CL] for this version) https://doi.org/10.48550/arXiv.2507.23095 @ Submission history From: Ishani Mondal [view email] [v1] Wed, 30 Jul 2025 20:52:34 UTC (2,803 KB) ‘Agent Framework for Human-Like Design Access Paper: View PDF TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.23083 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 30 Jul 2025) Context-aware Rotary Position Embedding Ali Veisi, Delaram Fartoot, Hamidreza Amirzadeh Positional encoding is a vital component of Transformer architectures, enabling models to incorporate sequence order into self-attention mechanisms. Rotary Positional Embeddings (ROPE) have become a widely adopted solution due to their compatibility with relative position encoding and computational efficiency. However, ROPE relies on static, input-independent sinusoidal frequency patterns, limiting its ability to model context-sensitive relationships. In this work, we propose CARoPE (Context-Aware Rotary Positional Embedding), a novel generalization of RoPE that dynamically generates head-specific frequency patterns conditioned on token embeddings. This design introduces token- and context-sensitive positional representations while preserving RoPE efficiency and architectural simplicity. CARoPE computes input-dependent phase shifts using a bounded transformation of token embeddings and integrates them into the rotary mechanism across attention heads. We evaluate CARoPE on the FineWeb-Edu-10B dataset using GPT-2 variants trained on next-token prediction tasks. Experimental results show that CARoPE consistently outperforms RoPE and other common positional encoding baselines, achieving significantly lower perplexity, even at longer context lengths. Additionally, CAROPE enables faster training throughput without sacrificing model stability. These findings demonstrate that CAROPE offers a scalable, expressive, and efficient upgrade to existing positional encoding strategies in Transformer models. Comments: 4 pages, 1 table Subjects: Computation and Language (cs.CL) Cite as: arXiv:2507.23083 [es.CL] (or arXiv:2507.23083V1 [es.CL] for this version) https://doi.org/10.48550/arXiv.2507.23083 @ Submission history Emam: Hamidraza Amirzadoh Iwiew amaill Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.23082 Help | Advanced Search All fields Computer Science > Computation and Language [Submitted on 30 Jul 2025] Exploring In-Context Learning for Frame-Semantic Parsing Diego Garat, Guillermo Moncecchi, Dina Wonsever Frame Semantic Parsing (FSP) entails identifying predicates and labeling their arguments according to Frame Semantics. This paper investigates the use of In-Context Learning (ICL) with Large Language Models (LLMs) to perform FSP without model fine-tuning. We propose a method that automatically generates task-specific prompts for the Frame Identification (Fl) and Frame Semantic Role Labeling (FSRL) subtasks, relying solely on the FrameNet database. These prompts, constructed from frame definitions and annotated examples, are used to guide six different LLMs. Experiments are conducted on a subset of frames related to violent events. The method achieves competitive results, with F1 scores of 94.3% for Fl and 77.4% for FSRL. The findings suggest that ICL offers a practical and effective alternative to traditional fine-tuning for domain-specific FSP tasks ‘Subjects: Computation and Language (cs.CL) Cite as: arXiv:2507.23082 [es.CL] (or arXiv:2507.23082v1 [es.CL] for this version) https:/doi.org/10.48550/arXiv.2507.23082 @ Submission history From: Diego Garat [view email] [v1] Wed, 30 Jul 2025 20:29:17 UTC (85 KB) Bibliographic Tools Code, Data, Media Demos Related Papers About arXivLabs Access Paper: View PDF HTML (experimental) TeX Source Other Formats View lense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark ed Bibliographic and Citation Tools
We gratefully a Search, ar Alv > cs > arXiv:2507.23063 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 30 Jul 2025] Math Natural Language Inference: this should be easy! Valeria de Paiva, Qiyue Gao, Hai Hu, Pavel Kovalev, Yikang Liu, Lawrence S. Moss, Zhiheng Qian We ask whether contemporary LLMs are able to perform natural language inference (NLI) tasks on mathematical texts. We call this the Math NLI problem. We construct a corpus of Math NLI pairs whose premises are from extant mathematical text and whose hypotheses and gold labels were provided by people with experience in both research-level mathematics and also in the NLI field. We also investigate the quality of corpora using the same premises but whose hypotheses are provided by LLMs themselves. We not only investigate the performance but also the inter-group consistency of the diverse group of LLMs. We have both positive and negative findings Among our positive findings: in some settings, using a majority vote of LLMs is approximately equivalent to using human-labeled data in the Math NLI area. On the negative side: LLMs still struggle with mathematical language. They occasionally fail at even basic inferences. Current models are not as prone to hypothesis-only “inference” in our data the way the previous generation had been. In addition to our findings, we also provide our corpora as data to support future work on Math NLL Comments: 9 pages plus appendices Subjects: Computation and Language (es.CL) MSG classes: 68750 ACM classes: 1.2.7 Cite as: arXiv:2507.23063 [es.CL] (or arXiv:2507.23063v1 [es.CL] for this version) https:/doi.org/10.48550/arXiv.2507.23063 @ Submission history From: Lawrence Moss [view email] [v1] Wed, 30 Jul 2025 19:49:04 UTC (32 KB) Access Paper: View PDF HTML (experimental) TeX Source Other Formats View lense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, All fields ar Alv > cs > arXiv:2507.22968 Help | Advanced Search Computer Science > Computation and Language [Submitted on 30 Jul 2025] C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations Chengqian Ma, Wei Tao, Yiwen Guo Spoken Dialogue Models (SDMs) have recently attracted significant attention for their ability to generate voice responses directly to users’ spoken queries. Despite their increasing popularity, there exists a gap in research focused on comprehensively understanding their practical effectiveness in comprehending and emulating human conversations. This is especially true compared to text-based Large Language Models (LLMs), which benefit from extensive benchmarking. Human voice interactions are inherently more complex than text due to characteristics unique to spoken dialogue. Ambiguity poses one challenge, stemming from semantic factors like polysemy, as well as phonological aspects such as heterograph, heteronyms, and stress patterns. Additionally, context-dependency, like omission, coreference, and multi-turn interaction, adds further complexity to human conversational dynamics. To illuminate the current state of SDM development and to address these challenges, we present a benchmark dataset in this paper, which comprises 1,079 instances in English and Chinese. Accompanied by an LLM-based evaluation method that closely aligns with human judgment, this dataset facilitates a comprehensive exploration of the performance of SDMs in tackling these practical challenges. ‘Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.Al) Cite as: arXiv:2507.22968 [es.CL] (or arXiv:2507.22968v1 [es.CL] for this version) https:/idoi.org/10.48550/arXiv.2507.22968 @ Submission history From: Chenggian Ma [view email] [v1] Wed, 30 Jul 2025 17:56:23 UTC (33,978 KB) Access Paper: View PDF HTML (experimental) TeX Source Other Formats View lense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.22944 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 25 Jul 2025] Opacity as Authority: Arbitrariness and the Preclusion of Contestation Naomi Omeonga wa Kayembe This article redefines arbitrariness not as a normative flaw or a symptom of domination, but as a foundational functional mechanism structuring human systems and interactions. Diverging from critical traditions that conflate arbitrariness with injustice, it posits arbitrariness as a semiotic trait: a property enabling systems - linguistic, legal, or social - to operate effectively while withholding their internal rationale. Building on Ferdinand de Saussure's concept of l'arbitraire du signe, the analysis extends this principle beyond language to demonstrate its cross- domain applicability, particularly in law and social dynamics. The paper introduces the "Motivation -> Constatability -> Contestability” chain, arguing that motivation functions as a crucial interface rendering an act's logic vulnerable to intersubjective contestation. When this chain is broken through mechanisms like "immotivization” or "Conflict Lateralization” (exemplified by "the blur of the wolf drowned in the fish"), acts produce binding effects without exposing their rationale, thus precluding justiciability. This structural opacity, while appearing illogical, is a deliberate design protecting authority from accountability. Drawing on Shannon's entropy model, the paper formalizes arbitrariness as A = H(L|M) (conditional entropy). It thereby proposes a modern theory of arbitrariness as a neutral operator central to control as well as care, an overlooked dimension of interpersonal relations. While primarily developed through human social systems, this framework also illuminates a new pathway for analyzing explainability in advanced artificial intelligence systems. ‘Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs Al); Computers and Society (cs.CY) Cite as: arXiv:2507.22944 [es.CL] (or arXiv:2507.22944V1 [es.CL] for this version) https:/idoi.org/10.48550/arXiv.2507.22944 @ Access Paper: View PDF Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al cs.CY References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.22943 Help | Advanced Search All fields Computer Science > Computation and Language [Submitted on 25 Jul 2025] A chart review process aided by natural language processing and multi-wave adaptive sampling to expedite validation of code-based algorithms for large database studies Shirley V Wang, Georg Hahn, Sushama Kattinakere Sreedhara, Mufaddal Mahesri, Haritha S. Pillai, Rajendra Aldis, Joyce Lii, Sarah K. Dutcher, Rhoda Eniafe, Jamal T. Jones, Keewan Kim, Jiwei He, Hana Lee, Sengwee Toh, Rishi J Desai, Jie Yang Background: One of the ways to enhance analyses conducted with large claims databases is by validating the measurement characteristics of code-based algorithms used to identify health outcomes or other key study parameters of interest. These metrics can be used in quantitative bias analyses to assess the robustness of results for an inferential study given potential bias from outcome misclassification. However, extensive time and resource allocation are typically re-quired to create reference-standard labels through manual chart review of free-text notes from linked electronic health records. Methods: We describe an expedited process that introduces efficiency in a validation study us-ing two distinct mechanisms: 1) use of natural language processing (NLP) to reduce time spent by human reviewers to review each chart, and 2) a multi-wave adaptive sampling approach with pre-defined criteria to stop the validation study once performance characteristics are identified with sufficient precision. We illustrate this process in a case study that validates the performance of a claims-based outcome algorithm for intentional self-harm in patients with obesity. Results: We empirically demonstrate that the NLP- assisted annotation process reduced the time spent on review per chart by 40% and use of the pre-defined stopping rule with multi-wave samples would have prevented review of 77% of patient charts with limited compromise to precision in derived measurement characteristics. Conclusion: This approach could facilitate more routine algorithms used to define key study parameters, ultimately enhancing understanding of the reliability of find-ings derived from database studies. Access Paper: View PDF Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by’ cs stat stat ME References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark AW
We gratefully a Search, ar Alv > cs > arXiv:2507.22941 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 25 Jul 2025] SigBERT: Combining Narrative Medical Reports and Rough Path Signature Theory for Survival Risk Estimation in Oncology Paul Minchella, Loic Verlingue, Stéphane Chrétien, Rémi Vaucher, Guillaume Metzler Electronic medical reports (EHR) contain a vast amount of information that can be leveraged for machine learning applications in healthcare. However, existing survival analysis methods often struggle to effectively handle the complexity of textual data, particularly in its sequential form. Here, we propose SigBERT, an innovative temporal survival analysis framework designed to efficiently process a large number of clinical reports per patient. SigBERT processes timestamped medical reports by extracting and averaging word embeddings into sentence embeddings. To capture temporal dynamics from the time series of sentence embedding coordinates, we apply signature extraction from rough path theory to derive geometric features for each patient, which significantly enhance survival model performance by capturing complex temporal dynamics. These features are then integrated into a LASSO-penalized Cox model to estimate patient-specific risk scores. The model was trained and evaluated on a real-world oncology dataset from the Léon Bérard Center corpus, with a C-index score of 0.75 (sd 0.014) on the independent test cohort. SigBERT integrates sequential medical data to enhance risk estimation, advancing narrative-based survival analysis. Comments: 12 pages, 2 figures, accepted for ECML PKDD 2025 Subjects: Computation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (cs.LG); Applications (stat.AP) Cite as: arXiv:2507.22941 [es.CL] (or arXiv:2507.22941V1 [es.CL] for this version) https://doi.org/10.48550/arXiv.2507.22941 @ Submission history From: Paul Minchella [view email] Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs.CY cs. LG stat statAP References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.22940 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 25 Jul 2025] Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes Rui Jiao, Yue Zhang, Jinku Li We present RELIANCE (Reasoning Evaluation with Logical Integrity and Accuracy for Confidence Enhancement), a novel framework addressing a critical vulnerability in Large Language Models (LLMs): the prevalence of factual inaccuracies within intermediate reasoning steps despite correct final answers. This phenomenon poses substantial risks in high-stakes domains including healthcare, legal analysis, and scientific research, where erroneous yet confidently presented reasoning can mislead users into dangerous decisions. Our framework integrates three core components: (1) a specialized fact-checking classifier trained on counterfactually augmented data to detect subtle factual inconsistencies within reasoning chains; (2) a Group Relative Policy Optimization (GRPO) reinforcement learning approach that balances factuality, coherence, and structural correctness through multi-dimensional rewards; and (3) a mechanistic interpretability module examining how factuality improvements manifest in model activations during reasoning processes. Extensive evaluation across ten state-of-the-art models reveals concerning patterns: even leading models like Claude-3.7 and GPT-o1 demonstrate reasoning factual accuracy of only 81.93% and 82.57% respectively. RELIANCE significantly enhances factual robustness (up to 49.90% improvement) while maintaining or improving performance on challenging benchmarks including Math-500, AIME-2024, and GPQA. Furthermore, our activation-level analysis provides actionable insights into how factual enhancements reshape reasoning trajectories within model architectures, establishing foundations for future training methodologies that explicitly target factual robustness through activation-guided optimization. ‘Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.Al) Cite as: arXiv:2507.22940 [es.CL] (or arXiv-2507.22940V1 [es.CL] for this version) Access Paper: View PDF HTML (experimental) TeX Source Other Formats REE view ticense Current browse context es.CL new | recent | 2025-07 Change to browse by’ cs cs Al References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark AW
We gratefully act ar XR \V > cs > arXiv:2507.22939 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 25 Jul 2025] PARROT: An Open Multilingual Radiology Reports Dataset Bastien Le Guellec, Kokou Adambounou, Lisa C Adams, Thibault Agripnidis, Sung Soo Ahn, Radhia Ait Chalal, Tugba Akinci D Antonoli, Philippe Amouyel, Henrik Andersson, Raphael Bentegeac, Claudio Benzoni, Antonino Andrea Blandino, Felix Busch, Elif Can, Riccardo Cau, Armando Ugo Cavallo, Christelle Chavihot, Erwin Chiquete, Renato Cuocolo, Eugen Divjak, Gordana Ivanac, Barbara Dziadkowiec Macek, Armel Elogne, Salvatore Claudio Fanni, Carlos Ferrarotti, Claudia Fossataro, Federica Fossataro, Katarzyna Fulek, Michal Fulek, Pawel Gac, Martyna Gachowska, Ignacio Garcia Juarez, Marco Gatti, Natalia Gorelik, Alexia Maria Goulianou, Aghiles Hamroun, Nicolas Herinirina, Krzysztof Kraik, Dominik Krupka, Quentin Holay, Felipe Kitamura, Michail E Klontzas, Anna Kompanowska, Rafal Kompanowski, Alexandre Lefevre, Tristan Lemke, Maximilian Lindholz, Lukas Muller, Piotr Macek, Marcus Makowski, Luigi Mannacio, Aymen Meddeb, Antonio Natale, Beatrice Nguema Edzang, Adriana Ojeda, Yae Won Park, Federica Piccione, Andrea Ponsiglione, Malgorzata Poreba, Rafal Poreba, Philipp Prucker, Jean Pierre Pruvo, Rosa Alba Pugliesi, Feno Hasina Rabemanorintsoa, Vasileios Rafailidis, Katarzyna Resler, Jan Rotkegel, Luca Saba, Ezann Siebert, Arnaldo Stanzione, Ali Fuat Tekin, Liz Toapanta Yanchapaxi, Matthaios Triantafyllou, Ekaterini Tsaoulia, Evangelia Vassalou, Federica Vernuccio, Johan Wasselius, Weilang Wang, Szymon Urban, Adrian Wlodarezak, Szymon Wlodarezak, Andrzej Wysocki, Lina Xu, Tomasz Zatonski, Shuhang Zhang, Sebastian Ziegelmayer, Gregory Kuchcinski, Keno K Bressem Rationale and Objectives: To develop and validate PARROT (Polyglottal Annotated Radiology Reports for Open Testing), a large, multicentric, open-access dataset of fictional radiology reports spanning multiple languages for testing natural language processing applications in radiology. Materials and Methods: From May to September 2024 radiologists were invited to contribute fictional radiology reports following their standard reporting practices. Access Paper: View PDF HTML (experimental) TeX Source Other Formats REE view ticense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark AH
We gratefully a Search, ar Alv > cs > arXiv:2507.22938 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 25 Jul 2025] A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents Sumit Soman, H. G. Ranjani, Sujoy Roychowdhury, Venkata Dharma Surya Narayana Sastry, Akshat Jain, Pranav Gangrade, Ayaaz Khan Question-Answering (QA) from technical documents often involves questions whose answers are present in figures, such as flowcharts or flow diagrams. Text-based Retrieval Augmented Generation (RAG) systems may fail to answer such questions. We leverage graph representations of flowcharts obtained from Visual large Language Models (VLMs) and incorporate them in a text-based RAG system to show that this approach can enable image retrieval for QA in the telecom domain. We present the end-to-end approach from processing technical documents, classifying image types, building graph representations, and incorporating them with the text embedding pipeline for efficient retrieval. We benchmark the same on a QA dataset created based on proprietary telecom product information documents. Results show that the graph representations obtained using a fine-tuned VLM model have lower edit distance with respect to the ground truth, which illustrate the robustness of these representations for flowchart images. Further, the approach for QA using these representations gives good retrieval performance using text-based embedding models, including a telecom-domain adapted one. Our approach also alleviates the need for a VLM in inference, which is an important cost benefit for deployed QA systems. Comments: Accepted for publication at the KDD 2025 Workshop on Structured Knowledge for Large Language Models, Subjects: Computation and Language (es.CL); Artificial Intelligence (cs.Al) MSG classes: 68750 ACM classes: 1.2.7 Cite as: arXiv:2507.22938 [es.CL] (or arXiv:2507.22938V1 [es.CL] for this version) Access Paper: View PDF HTML (experimental) TeX Source Other Formats View lense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.22937 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 25 Jul 2025] CoE-Ops: Collaboration of LLM-based Experts for AlOps Question-Answering Jinkun Zhao, Yuanshuai Wang, Xingjian Zhang, Ruibo Chen, Xingchuang Liao, Junle Wang, Lei Huang, Kui Zhang, Wenjun Wu With the rapid evolution of artificial intelligence, AlOps has emerged as a prominent paradigm in DevOps. Lots of work has been proposed to improve the performance of different AlOps phases. However, constrained by domain-specific knowledge, a single model can only handle the operation requirement of a specific task,such as log parser,root cause analysis. Meanwhile, combining multiple models can achieve more efficient results, which have been proved in both previous ensemble learning and the recent LLM training domain. Inspired by these works, to address the similar challenges in AIOPS, this paper first proposes a collaboration-of-expert framework(CoE-Ops) incorporating a general-purpose large language model task classifier. A retrieval- augmented generation mechanism is introduced to improve the framework's capability in handling both Question- Answering tasks with high-level(Code, build, Test,etc.) and low-level(fault analysis,anomaly detection, etc.). Finally, the proposed method is implemented in the AlOps domain, and extensive experiments are conducted on the DevOps-EVAL dataset. Experimental results demonstrate that CoE-Ops achieves a 72% improvement in routing accuracy for high-level AlOps tasks compared to existing CoE methods, delivers up to 8% accuracy enhancement over single AlOps models in DevOps problem resolution, and outperforms larger-scale Mixture-of- Experts (MoE) models by up to 14% in accuracy. ‘Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.Al) Cite as: arXiv:2507.22937 [es.CL] (or arXiv:2507.22937V1 [es.CL] for this version) https:/idoi.org/10.48550/arXiv.2507.22937 @ Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a ar Alv > cs > arXiv:2507.22936 Search, All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 24 Jul 2025] Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis Md Talha Mohsin Language Models (LLMs) have demonstrated remarkable capabilities across a wide variety of Financial Natural Language Processing (FinNLP) tasks. However, systematic comparisons among widely used LLMs remain underexplored. Given the rapid advancement and growing influence of LLMs in financial analysis, this study conducts a thorough comparative evaluation of five leading LLMs, GPT, Claude, Perplexity, Gemini and DeepSeek, using 10-K filings from the ‘Magnificent Seven' technology companies. We create a set of domain- specific prompts and then use three methodologies to evaluate model performance: human annotation, automated lexical-semantic metrics (ROUGE, Cosine Similarity, Jaccard), and model behavior diagnostics (prompt-level variance and across-model similarity). The results show that GPT gives the most coherent, semantically aligned, and contextually relevant answers; followed by Claude and Perplexity. Gemini and DeepSeek, on the other hand, have more variability and less agreement. Also, the similarity and stability of outputs change from company to company and over time, showing that they are sensitive to how prompts are written and what source material is used Comments: 22 Pages, 6 Tables, 7 Figures Subjects: Computation and Language (¢s.CL); Artificial Intelligence (cs.A\l); Computational Engineering, Finance, and Science (cs.CE);, Human-Computer Interaction (cs. HC); Computational Finance (q-fin.CP) Cite as: _arXiv:2507.22936 [es.CL] (or arXiv:2507 229361 [es.CL] for this version) https://doi.org/10.48550/arxiv.2507.22936 @ Submission history Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al cs.CE cs. HC a-fin a-fin.cP References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.22935 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 24 Jul 2025] Trusted Knowledge Extraction for Operations and Maintenance Intelligence Kathleen Mealey, Jonathan A. Karr Jr., Priscila Saboia Moreira, Paul R. Brenner, Charles F. Vardeman II Deriving operational intelligence from organizational data repositories is a key challenge due to the dichotomy of data confidentiality vs data integration objectives, as well as the limitations of Natural Language Processing (NLP) tools relative to the specific knowledge structure of domains such as operations and maintenance. In this work, we discuss Knowledge Graph construction and break down the Knowledge Extraction process into its Named Entity Recognition, Coreference Resolution, Named Entity Linking, and Relation Extraction functional components. We then evaluate sixteen NLP tools in concert with or in comparison to the rapidly advancing capabilities of Large Language Models (LLMs). We focus on the operational and maintenance intelligence use case for trusted applications in the aircraft industry. A baseline dataset is derived from a rich public domain US Federal Aviation Administration dataset focused on equipment failures or maintenance requirements. We assess the zero-shot performance of NLP and LLM tools that can be operated within a controlled, confidential environment (no data is sent to third parties). Based on our observation of significant performance limitations, we discuss the challenges related to trusted and LLM tools as well as their Technical Readiness Level for wider use in mission-critical industries such as aviation. We conclude with recommendations to enhance trust and provide our open-source curated dataset to support further baseline testing and evaluation. ‘Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.Al) arXiv:2507.22935 [es.CL] (or arXiv:2507.22935v1 [es.CL] for this version) https:/idoi.org/10.48550/arXiv.2507.22935 @ Cite as: Submission history Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.22934 Help | Advanced Search All fields Computer Science > Computation and Language [Submitted on 24 Jul 2025] Deep Learning Approaches for Multimodal Intent Recognition: A Survey Jingwei Zhao, Yuhua Wen, Qifei Li, Minchi Hu, Yingying Zhou, Jingyao Xue, Junyang Wu, Yingming Gao, Zhengqi Wen, Jianhua Tao, Ya Li Intent recognition aims to identify users’ underlying intentions, traditionally focusing on text in natural language processing. With growing demands for natural human-computer interaction, the field has evolved through deep learning and multimodal approaches, incorporating data from audio, vision, and physiological signals. Recently, the introduction of Transformer-based models has led to notable breakthroughs in this domain. This article surveys deep learning methods for intent recognition, covering the shift from unimodal to multimodal techniques, relevant datasets, methodologies, applications, and current challenges. It provides researchers with insights into the latest developments in multimodal intent recognition (MIR) and directions for future research. Comments: Submitted to ACM Computing Surveys ‘Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.All) Cite as: —_arXiv:2507.22934 [es.CL] (or arXiv:2507.22934V1 [es.CL] for this version) https://doi.org/10.48550/arXiv.2507 22934 @ Submission history From: Yuhua Wen [view email] [v4] Thu, 24 Jul 2025 17:12:01 UTC (3,589 KB) Bibliographic Tools Code, Data, Media Demos Related Papers About arXivLabs Access Paper: View PDF HTML (experimental) TeX Source Other Formats View lense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.22933 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 24 Jul 2025] Augmented Vision-Language Models: A Systematic Review Anthony C Davis, Burhan Sadiq, Tianmin Shu, Chien-Ming Huang Recent advances in visual-language machine learning models have demonstrated exceptional ability to use natural language and understand visual scenes by training on large, unstructured datasets. However, this training paradigm cannot produce interpretable explanations for its outputs, requires retraining to integrate new information, is highly resource-intensive, and struggles with certain forms of logical reasoning. One promising solution involves integrating neural networks with external symbolic information systems, forming neural symbolic systems that can enhance reasoning and memory abilities. These neural symbolic systems provide more interpretable explanations to their outputs and the capacity to assimilate new information without extensive retraining. Utilizing powerful pre-trained Vision-Language Models (VLMs) as the core neural component, augmented by extemal systems, offers a pragmatic approach to realizing the benefits of neural-symbolic integration. This systematic literature review aims to categorize techniques through which visual-language understanding can be improved by interacting external symbolic information systems. ‘Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.Al) Cite as: arXiv:2507.22933 [es.CL] (or arXiv:2507.22933v1 [es.CL] for this version) https:/idoi.org/10.48550/arXiv.2507.22933 @ Submission history From: Anthony C. Davis [view email] [v4] Thu, 24 Jul 2025 16:27:38 UTC (906 KB) | Bibliographic Tools | Code. Data, Media Demos Related Papers ‘About arXivLabs Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.22932 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 24 Jul 2025] FinMarBa: A Market-Informed Dataset for Financial Sentiment Classification Baptiste Lefort, Eric Benhamou, Beatrice Guez, Jean-Jacques Ohana, Ethan Setrouk, Alban Etienne This paper presents a novel hierarchical framework for portfolio optimization, integrating lightweight Large Language Models (LLMs) with Deep Reinforcement Learning (DRL) to combine sentiment signals from financial news with traditional market indicators. Our three-tier architecture employs base RL agents to process hybrid data, meta-agents to aggregate their decisions, and a super-agent to merge decisions based on market data and sentiment analysis. Evaluated on data from 2018 to 2024, after training on 2000-2017, the framework achieves a 26% annualized return and a Sharpe ratio of 1.2, outperforming equal-weighted and S&P 500 benchmarks. Key contributions include scalable cross-modal integration, a hierarchical RL structure for enhanced stability, and open-source reproducibility. Comments: 8 pages Subjects: Computation and Language (es.CL); General Finance (q-fin.GN) Cite as: _arXiv:2507.22932 [es.CL] (or arXiv:2507.22932v1 [es.CL] for this version) https://doi.org/10.48550/arXiv.2507 22932 @ Submission history From: Eric Benhamou [view email] [v4] Thu, 24 Jul 2025 16:27:32 UTC (387 KB) Bibliographic Tools Code, Data, Media Demos Related Papers About arXivLabs Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs a-fin a-fin.GN References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark ed
We gratefully a Search, All fields ar Alv > cs > arXiv:2507.22931 Help | Advanced Search Computer Science > Computation and Language Access Paper: [Submitted on 24 Jul 2025] View PDF Enhancing RAG Efficiency with Adaptive Context Compression HTM (experimental) Shuyu Guo, Zhaochun Ren Other Formats Retrieval-augmented generation (RAG) enhances large language models (LLMs) with external knowledge but en rowse context: cs.CL incurs significant inference costs due to lengthy retrieved contexts. While context compression mitigates this, issue, existing methods apply fixed compression rates, over-compressing simple queries or under-compressing complex ones. We propose Adaptive Context Compression for RAG (ACC-RAG), a framework that dynamically . Change to browse by: adjusts compression rates based on input complexity, optimizing inference efficiency without sacrificing accuracy. os ACC-RAG combines a hierarchical compressor (for multi-granular embeddings) with a context selector to retain cs.Al minimal sufficient information, akin to human skimming. Evaluated on Wikipedia and five QA datasets, ACC-RAG outperforms fixed-rate methods and matches/unlocks over 4 times faster inference versus standard RAG while new | recent | 2025-07 References & Citations NASAADS Google Scholar Semantic Scholar maintaining or improving accuracy. ‘Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.Al) Export BibTeX Citation Cite as: arXiv:2507.22931 [es.CL] (or arXiv:2507.22931v1 [es.CL] for this version) Bookmark https://doi.org/10.48550/arXiv.2507.22031 @ ¥ Submission history From: Shuyu Guo [view email] [v1] Thu, 24 Jul 2025 13:46:51 UTC (943 KB) Bibliographic Tools Code, Data, Media Demos Related Papers About arXivLabs
We gratefully a Search, ar Alv > cs > arXiv:2507.22930 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 24 Jul 2025] Protecting Vulnerable Voices: Synthetic Dataset Generation for Self-Disclosure Detection Shalini Jangra, Suparna De, Nishanth Sastry, Saeed Fadaei Social platforms such as Reddit have a network of communities of shared interests, with a prevalence of posts and comments from which one can infer users’ Personal Information Identifiers (Pls). While such self-disclosures can lead to rewarding social interactions, they pose privacy risks and the threat of online harms. Research into the identification and retrieval of such risky self-disclosures of Plis is hampered by the lack of open-source labeled datasets. To foster reproducible research into Pll-revealing text detection, we develop a novel methodology to create synthetic equivalents of Pll-revealing data that can be safely shared. Our contributions include creating a taxonomy of 19 Pll-revealing categories for vulnerable populations and the creation and release of a synthetic Pll-labeled multi-text span dataset generated from 3 text generation Large Language Models (LLMs), Llama2-7B, Llama3-8B, and zephyr-7b-beta, with sequential instruction prompting to resemble the original Reddit posts. The utility of our methodology to generate this synthetic dataset is evaluated with three metrics: First, we require reproducibility equivalence, i.e., results from training a model on the synthetic data should be comparable to those obtained by training the same models on the original posts. Second, we require that the synthetic data be unlinkable to the original users, through common mechanisms such as Google Search. Third, we wish to ensure synthetic data be indistinguishable from the original, i.e., trained humans should not be able to tell them apart. We release our dataset and code at this https URL to reproducible research into Pll privacy risks in online social media Comments: 15 pages, 4 Figures, Accepted in "The 17th Intemational Conference on Advances in Social Networks Analysis and Mining - ASONAM-2025" Subjects: Computation and Language (es.CL); Social and Information Networks (cs.Sl) Cite as: arXiv:2507.22930 [es.CL] Access Paper: View PDF HTML (experimental) TeX Source Other Formats REE view ticense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs.SI References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark AW
We gratefully a Search, ar Alv > cs > arXiv:2507.22929 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 24 Jul 2025] EH-Benchmark Ophthalmic Hallucination Benchmark and Agent- Driven Top-Down Traceable Reasoning Workflow Xiaoyu Pan, Yang Bai, Ke Zou, Yang Zhou, Jun Zhou, Huazhu Fu, Yih-Chung Tham, Yong Liu Medical Large Language Models (MLLMs) play a crucial role in ophthalmic diagnosis, holding significant potential to address vision-threatening diseases. However, their accuracy is constrained by hallucinations stemming from limited ophthalmic knowledge, insufficient visual localization and reasoning capabilities, and a scarcity of multimodal ophthalmic data, which collectively impede precise lesion detection and disease diagnosis. Furthermore, existing medical benchmarks fail to effectively evaluate various types of hallucinations or provide actionable solutions to mitigate them. To address the above challenges, we introduce EH-Benchmark, a novel ophthalmology benchmark designed to evaluate hallucinations in MLLMs. We categorize MLLMs' hallucinations based on specific tasks and error types into two primary classes: Visual Understanding and Logical Composition, each comprising multiple subclasses. Given that MLLMs predominantly rely on language-based reasoning rather than visual processing, we propose an agent-centric, three-phase framework, including the Knowledge-Level Retrieval stage, the Task-Level Case Studies stage, and the Result-Level Validation stage. Experimental results show that our multi-agent framework significantly mitigates both types of hallucinations, enhancing accuracy, interpretability, and reliability. Our project is available at this https URL. ‘Comments: 9 figures, 5 tables. submit/6621751 ‘Subjects: Computation and Language (es.CL); Computer Vision and Pattern Recognition (cs.CV); Multiagent Systems (cs. MA) Cite as: _arXiv:2507.22929 [es.CL] (or arXiv:2507.22929V1 [es.CL] for this version) https://doi.org/10.48550/arXiv.2507.22929 @ Submission history Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs.CV cs.MA References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
We gratefully a Search, ar Alv > cs > arXiv:2507.22928 All fields Help | Advanced Search Computer Science > Computation and Language [Submitted on 24 Jul 2025] How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding Xi Chen, Aske Plaat, Niki van Stein Chain-of thought (CoT) prompting boosts Large Language Models accuracy on multi-step tasks, yet whether the generated "thoughts" reflect the true internal reasoning process is unresolved. We present the first feature-level causal study of CoT faithfulness. Combining sparse autoencoders with activation patching, we extract monosemantic features from Pythia-70M and Pythia-2.8B while they tackle GSM8K math problems under CoT and plain (noCoT) prompting. Swapping a small set of CoT-reasoning features into a noCoT run raises answer log-probabilities significantly in the 2.88 model, but has no reliable effect in 70M, revealing a clear scale threshold. CoT also leads to significantly higher activation sparsity and feature interpretability scores in the larger model, signalling more modular internal computation. For example, the model's confidence in generating correct answers improves from 1.2 to 4.3. We introduce patch-curves and random-feature patching baselines, showing that useful CoT information is not only present in the top-K patches but widely distributed. Overall, our results indicate that CoT can induce more interpretable internal structures in high-capacity LLMs, validating its role as a structured prompting method. ‘Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.Al) Cite as: arXiv:2507.22928 [es.CL] (or arXiv:2507.22928v1 [es.CL] for this version) https:/idoi.org/10.48550/arXiv.2507.22928 @ Submission history From: Xi Chen [view email] [v4] Thu, 24 Jul 2025 10:25:46 UTC (3,184 KB) Access Paper: View PDF HTML (experimental) TeX Source Other Formats COREE) view tcense Current browse context es.CL new | recent | 2025-07 Change to browse by: cs cs Al References & Citations NASAADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark
Raise your hand if you speak another language out of the English.
Okay, now raise your hand if English is not your first language.
Okay, a few hands up.
So according to the 2021 census, nearly one in four Canadians are immigrants or permanent
That means that almost 25% of Canada's population are foreign more.
Although Canada celebrates individuals diverse cultures and ethnicities, people who immigrate
to Canada may still experience a culture ration.
A culture ration is the graduate process where one adapts to a new cultural environment
upon relocating from their heritage culture to a new and prevailing host culture in which
Well, inculturation is when one maintains their heritage cultures' values and traditions.
Immigrants usually integrate themselves into their new host culture by adopting the values
and traditions from the new host culture while still maintaining some of the values and
traditions from their heritage culture.
Now first language loss or L1 loss is a documented phenomenon that happens when individuals
progressively lose their first language.
And this is especially common among those who relocate to a country that speaks a foreign
language that differs from their first language.
Research has shown that the loss of first language proficiency has detrimental consequences,
such as a loss of culture and ethnic identity.
Therefore, my thesis aimed to look at prominent factors such as a culture ration that may
be related to first language loss and inculturation which may relate to first language retention.
For this study, we had 177 undergraduate students complete a series of surveys that measure
their English vocabulary size, levels of acculturation to the host culture, and language dominance.
This depends also completed a 101 Zoom session that looked at their language proficiency
in both their first language and in English.
We found that the more acculturated a person is, the lower their first language skills are.
However, they did have higher English language proficiency.
On the contrary, inculturation is related to individual's first language maintenance,
belower English outcomes.
We also looked at whether residing a multigenerational household will help individuals preserve their
However, we did not find any significant result that supported that claim.
The findings of the present study highlights the importance of acculturation and first language
Implying that higher levels of acculturation is associated with lower levels of first language
While it's important to acquire the new dominant language of the society and adopt the values
and traditions from the host culture, it's also critical to meet you once first language
and heritage culture as well.
Welcome everybody to my presentation. Let me start by asking you one simple question. Do you remember the pandemic?
Yeah, yeah, well in the interest of time, let me skip straight to the answer and the answer is yes of course
We all remember how tough it was
But we have one great weapon and now we're disposed against COVID and that were the mRNA vaccines
You've been probably hearing this word many many time mRNA
It is an incredible technology, but unfortunately it suffers from one major flow
This vaccines always need to be kept in the cold always in a freezer always in a fridge
And this is a massive issue in the developing world millions of doses have been estimated to be wasted
Chuck it out in the beans like leftover left on your table in the morning
And imagine how many lives could have been saved if we had a better version of this vaccine
This is what I want to change and my solution may come from the nice little protein that you see at the
Center of my screen that one ladies and gentlemen is known as an encapsulin and if you're wondering what it is
Well simply put an encapsulin is just a box a container something that you can open up put stuff on the inside
And that stuff stays there protected and the reason why I also put a volcano in my slide despite some of the puzzle looks
There's a round is because that gives a very good indication where you find the proteins in the most dangerous places
Anurfor and also out of they are for all in thirds and purposes and encapsulin this type of box is nigh in the
Structible is very very hard to break them apart
So you probably see where this is going
What if we were to combine the mRNA with its incredible potential as a vaccine
With a put it inside such a strong container something that could act as a safe to protect this medicine
Something that would allow us to create a new generation of vaccines that can be shipped all over the world and provide protection to everybody
Regardless of the conditions
This is and I'm not even joking why why what my entire PhD is all about in my first year
I focus on making as many as this box is as a good like in a factory
In my second and third year
I instead focus on trying to physically put this mRNA inside this box and to make sure that it works
I'm happy to announce you with you that we have a working prototype of this prototype of this vaccine
Then now we can move to the final stage the stage of test asking questions like is this going to be a tough vaccine a vaccine that can survive
All sorts of condition is this a vaccine that can be shipped all over the world for everybody is this vaccine going to be useful
Is he going to be provide protection for the people that need it?
These are all big questions and I know it's time is on the important matter here
But I'm pretty sure that the answer is going to be yes. Thank you for your time
Have you ever wondered how fast your reaction time is?
On the count of three, clap once as quickly as you can.
Not yet. On my count.
That quick reaction, a perfect harmony between your brain and body,
is something we often take for granted.
But however, there are millions of people with Alzheimer's and Parkinson's disease,
who slow down becomes a daily reality when they can't do such reactions.
Simple things like walking smoothly, clapping your hands,
or remembering these wonderful faces become increasingly difficult.
Right now, doctors rely on very expensive brain scans,
and invasive tests that only provide a brave snapshot of what's happening in your brain and body.
It's like trying to understand an entire movie's plot from just one pause scene.
Clearly, we need a better way.
My research addresses this gap using two powerful tools,
artificial intelligence, AI, and everyday physiological signals.
I measure physiological signals like brain activity using a portable EEG headset,
your heart rate activity using your smartwatch,
and your walking pattern using video recordings.
Then, I train AI to add like a skill detected that constantly spots clues
and changes in someone's daily movements.
They're speaking patterns, or even their typing speed.
It learns what normal looks like for each person,
so it can detect tiny shifts long before they become noticeable symptoms.
But I'm not stopping at looking at these signals individually.
I'm also exploring how these signals interact with each other
to provide a richer picture of the brain's communication network.
Imagine your brain and body as musicians in an orchestra.
Usually, they're perfectly synchronized.
In Alzheimer's or Parkinson's, though,
some instruments gradually fall out of sync or stop playing all together.
By tracking these disruptions, we can spot early signs of disease progression a lot sooner.
This early detection matters enormously
because it means interventions, like drugs and other treatments,
can start sooner to reduce the damages the diseases can cause.
Imagine being able to track your brain health as easily as you can see your daily steps
or even knowing your heart rate activity right from the comfort of your home.
Okay, now let's finish with one more synchronized count on my count.
Ready? One, two, three.
Next time you clap, whether it's cheering at a game
or celebrating a loved one celebration,
remember, these are the moments I'm working so hard to protect.
Two months ago, a train carrying environmentally hazardous chemicals derailed in Ohio, putting
the local population at risk.
However, we rely on these chemicals in order to produce our medicines, dyes, and more,
such as the case for the nitration reaction, a reaction that installs one nitrogen and
two oxygens onto a molecule.
In industry, this reaction uses harsh acids.
However, we know that certain bacteria and fungi perform the same reaction in nature
under environmentally friendly conditions.
In order to leverage nature's chemistry and develop a greener method to produce these
medicines and dyes, I decided to investigate the rules that nature has in place to perform
Now specifically, there are two proteins we know of that perform the nitration reaction.
I decided to zero in on the lesser studied of the two, a protein called rough O. As we
can see in the central green circle, I was successful in crystallizing rough O, making
Doing so allowed me to hit the crystal with X-rays, which produced a set of diffraction
images from which I was able to pull out structural information.
And this methodology worked.
I have generated the second ever structure of a protein that performs this nitration
A wise man once said, first is the worst and second is the best.
And third is the one with the treasure chest.
Or maybe that's something my friend in elementary school told me.
But naturality being second is a big deal because it's allowed me to look at the core of
my protein, rough O, the site of where the chemistry actually happens and compare it to
that of the first structure.
Interestingly, the core of rough O is widely different at key positions compared to the
first structure as there are less charges and it's more open.
This is highly unusual as proteins with a similar function often have a very similar structure.
These results suggest that the nitration reaction is far more complex than we originally
anticipated, which may allow us a higher level of control when designing our own reactions.
As a next step, I've identified over 50 proteins that may perform this nitration reaction
using online searches.
These proteins serve as the aforementioned treasure chest.
By analyzing this larger set of structures, I'll be able to completely uncover the rules
nature has for this reaction.
Currently, the nitration reaction used to produce our medicines and dyes follows this industrial
My research promotes a future where nature's chemistry is leveraged to perform the same
reaction, get the same medicines and dyes without the need for environmentally hazardous
This one's for you, Ohio.
The cardiovascular system is truly amazing.
We may not often think about it, but our hearts are beating constantly, delivering oxygen
and nutrients throughout our bodies.
Blood exits the heart through our largest blood vessel, the aorta.
In healthy individuals, the aorta is elastic.
When the heart beats, it ejects fast amounts of blood at enormously high pressure, and
similar to a rubber band, the aorta stretches to contain the sudden rush of energy, and
then relaxes, evenly distributing blood throughout our body.
In a condition called supervalvular aortic stenosis, or SVAS affecting 1,000 to 10,000 people,
the situation is not so simple.
In SVAS, this elasticity is missing.
There is no working rubber band.
Instead, to deal with these enormous pressure changes from the heart, the smooth muscle cells
of the aorta grow uncontrollably.
Making if we make the wall thicker, it will be strong and won't crack.
Unfortunately, this causes the aorta to become narrower, ultimately making it harder for
the heart to deliver enough nutrition to the body.
Eventually, this stressful process causes the heart to shut down, and sadly, there was
currently no care for this condition.
In my research, I study the differences between cells that make up a healthy aorta from
those of a person with SVAS.
Now I can't easily obtain cells directly from an aorta, as this would essentially require
However, using a technique called induced pluripotency, I can instead take a small sample
of skin cells and transform them into stem cells, which can then be directed to become
any type of cell in the body.
Imagine a stem cell as like a seed of untapped potential, and depending on how you cultivate
its growth and when and which nutrients you provide, it could become something as hardy
as a beat or something as beautiful as an orchid.
That might sound crazy, but here's how it's done.
Simply by adding a series of factors that are highly abundant in developing embryos, I
can divert those skin cells to a stem cell like state.
I can then cultivate these stem cells with specific nutrients to transform them into
smooth muscle cells that have the same DNA and characteristics as those taken directly
No open heart surgery required.
Using the stem cell model, I've been able to effectively study and directly test therapies
on SVAS smooth muscle cells.
In SVAS cells, the machinery that helps cells sense stress doesn't work properly, causing
them to miss cues from the heart and grow inappropriately.
I have discovered a compound that gives SVAS cells the blueprints to synthesize new rubber
band-like structures that can restore that stress-sensing capability.
I have shown that SVAS cells treated with this drug begin to behave similarly to healthy
cells, and I'm hopeful that my rescue experiments will help treat patients with this condition
in the not too distant future.
And as stem cells can become any type of cell, I can use them to study a multitude of
diseases, including cancer, and even COVID-19, and directly test therapies on any organ
system, in any individual, including you, and including me.
So, for the next few moments, I'm going to tell you why I'm doing my PhD and I'm going
to tell you Rachel's story.
So, I would like you to imagine that you have a four-year-old daughter.
She is standing in front of you and she is crying.
She's really her herself.
Her father is looking on and he is laughing.
He's laughing at his own granddaughter crying.
This is not the man you know.
This is a symptom of his dementia and it's getting worse.
At age 59, he was diagnosed with frontal temporal dementia and symptoms include things
It's a progressive condition, meaning he'll only get worse.
In going to your doctor, you found out that he has a hereditary form and you carried
the same faulty gene.
You will also get this awful condition.
As you look down at your four-year-old daughter, you know that she has a 50% chance of that
This is Rachel's life.
This is the reality if someone living with frontal temporal dementia.
However, there is hope.
We are currently in an era of clinical trials for dementia and there are actually some treatments
in the pipeline for this specific form.
However, we currently don't have accurate ways to measure where these treatments actually
work so they can be approved and not rejected.
So how can we do this?
Well as part of my PhD, I look in body fluids and this is things like blood.
And to do this, I use something called a sandwich assay.
And this is not as tasty as it sounds.
It's a way to look in the differences between Rachel's blood and people who don't carry
So what have I found?
Well, one major finding for my PhD is interplay between two key molecules, they're known as
progranialin, shown here in purple and prasapsin in orange.
For some context, in our brains, these molecules act like best friends that often found together
and they have very similar roles in our brains to keep them functioning as they should.
However, in the blood of people like Rachel, we found there was reduced levels of progranialin
and increased levels of prasapsin.
This difference could explain what's going wrong in the brain and why we develop symptoms
like we see in Rachel's father.
Well, five years ago, these trials did not exist and there was limited hope.
Now they do exist but we don't have great ways to measure where they actually work.
Hopefully this research can change that.
Tras that actually restored the balance of these two molecules could help us solve the puzzle
of frontal temporal dementia.
Now is the time for Rachel and for her young daughter.
Thank you for listening.
Think of one thing everyone here will do today, regardless of their age, race, gender,
My answer is that everybody will use the toilet because my project uses wastewater or
raw sewage to track infectious disease.
During the COVID-19 pandemic, many regions of Canada began using wastewater testing to
monitor for COVID-19.
This clinical testing has slowed down wastewater testing has become one of our most reliable
tools to monitor COVID-19 disease trends in some rural communities even prevented outbreaks
using this information.
So how can you track infectious disease using sewage?
Well, for certain infections, viral or bacterial particles are shed in urine or stool and
those particles end up in computerity sewage.
We can isolate those particles using tiny filters and extract their genetic material to
determine if a particular pathogen was present and if so, how much was present?
Because sewage is communal, the data collected is unbiased with coverage from every resident.
Well, because everybody poops.
After the success of using wastewater testing for COVID-19, some communities were interested
in using wastewater testing for other pathogens too, including sexually transmitted infections
My job is to develop wastewater tests for common STIs in Canada.
Bacterial STIs like gonorrhea have increased by 400 to 500% over the past decade.
This is likely an underestimate since just like with COVID-19, there are huge gaps in our
These gaps arise because STIs are asymptomatic in 50 to 70% of people for years or even
decades at a time so many people don't know they're infected.
Additionally, geographic and social barriers create inequitable access to healthcare for
many Canadians, but especially for those living in Northern Canada where the rates of STIs
are 10 to 20 times the national average.
Improved surveillance of STIs is also very important because for women, the first symptom
can be severe, including pelvic inflammatory disease, infertility, miscarriage, or even
Because people who are asymptomatic or unable to access testing still shed infectious particles
in their urine or stool, wastewater testing could help public health identify regions
with high rates of STIs.
This would allow public health to target healthcare and education resources to the communities
Overall targeted allocation of resources to affected communities represents an equitable
allocation of healthcare resources for all.
Just think, the road to more equitable access to healthcare could start with something as
simple as a trip to the bathroom.
Hello everyone, I'm Villem and I'll be walking you through the setup for latest Anopee paper
into the organization and surrounding formalsums.
First of all, what's the organization in Vadovee needed?
There are many word types and languages and most Anopee models required to have a predefined
vocabulary for which we have, for example, different embeddings.
If you took each word as a separate unit, then we would have vocabulary size of maybe 1 million,
which is paromatic out of multiple reasons.
On the other hand, if you separated each word as a sequence of characters,
then we would get very long sequences and semantic embeddings for each unit that
has characters who would be meaningless.
The solution is maybe somewhere in between where we split first into some chunks.
But there are many possible ways to do this organization and which one is the best one.
The best organization is such that it maximizes the performance of some downstream Anopee model.
So we can generate multiple organizations and train a model on to pull this
organization and take a look at performance.
There is an issue with this.
For example, in the context of mission translation,
the utilization takes just a few minutes as well as the evaluation using automatic metrics.
However, training the mission translation model from scratch takes at least a week on a single GPU.
Using this evaluation method of tokenizations quickly becomes unsustainable.
Now the question becomes how can we select the best organization we have actually
having to train the whole model?
The first option is to just use by far encoding, whether for vocabulary size of 32,000 tokens.
This will cover most application cases.
However, if you are interested more in principle understanding of the organization,
We can, for example, look at the token distribution and look at its style and look
if there are any tokens that occur very infrequently.
If they do, we can say that this is not a good organization because the models won't be able to learn
the correct meaning of those low frequency tokens.
However, this is a very hand-vavie evaluation approach.
If you look at these two different distributions, which one is better?
One way to look at it is that it's the one underwrite and the reason is that the token frequencies
So now we are looking for some magical distribution that tells us how uniform it is.
An entropy turns out to be a very good tool because it measures how spread out distribution is.
In the paper, we use more complex measures such as efficiency and droning entropy,
which also tell us something more about the nature of the organization.
Let's compare this predictive measure with the sequence length,
that is how many tokens on average are into the connoisseur segments.
In these graphs, each point is a separate organization and an anti-system.
The Y axis is the performance as measured by the Y and the X axis is the predictor.
Clearly, the rainy entropy is much better at performance prediction than the sequence length.
In our paper, we deal up rules which justify and explain why rainy efficiency is a good predictor
and compare it to many others.
We also go into much more detail than the space of this video allows.
Thanks for listening and let me know if you have any questions.
Also take a look at our other paper which deals with specific organization approach.
We are often told that you should eat rich food in moderation, but if you were the fresh
water snails I study, your strategy instead would be to eat as much rich food as possible.
Snails use the energy from this food to grow, reproduce, move, and do one other important
thing, release parasites into the water.
These parasites can also cause human infections, such as the devastating neglected tropical
disease, chistosomyasis, which is what I study.
Humans become infected with chistosomyasis when they encounter these free living parasites
in the water that are released by snails.
And the more parasites that are in the water, the higher the infection risk to humans.
And the most important thing for you to understand about this system is that snails produce more
parasites when they have access to rich, abundant food.
The problem for the snails is that they don't actually have access to high quality food
constantly in their environment.
As you can see, usually food that's rich comes in pulses, caused by events like heavy
rain, bringing in fertilizer runoff or sewage overflow into these water bodies.
And this nutrient pollution that causes food pulses can make it so that, that's why we
The nutrient pollution that comes in there also causes these unexpected consequences.
So what I mean by unexpected consequences is if I give an individual snail food that's
really rich, it's going to be obvious what happens to it.
It's going to get bigger, it's going to reproduce, and it's going to make a lot of parasites.
But at the ecological community level, we don't have just individuals.
We have individuals of different traits.
They're not identical.
So they may be a different size.
They may be differently reproductively mature.
Some may be infected, some may not be.
And it's the mix of these traits together that determines how intensely they compete
with each other for food.
And that's important to study, even though it's hard, because how much food they have tells
us how many parasites they can make because of how much energy is available for them.
So even though it's hard, and it's still important to do, how are we going to do this?
How are we going to predict what happens at the community level?
My dissertation uses disease ecology to do just that.
In general, my dissertation studies how mixes of snail traits and also things like their
environment or their food quality impact how many parasites they make.
I did a simulation study where I had snails in this huge population and their parasites.
And I did it over a transmission season.
So what I found is that you have a food pulse in the middle of the transmission season.
That's going to cause the most parasites to happen as opposed to any other pulse in
The reason why this period of time is so critical is because snails have been around long
enough to mature, to become heavily infected, and they're about to starve to death because
they're competing with each other.
This food pulse comes in, rescues them from starvation, and makes it so they have plenty
of parasites to eat.
I've tested this in my little fake ponds, and I found the same thing too.
So in conclusion, I guess what I'm telling you is that timing is everything, especially
Let me introduce you to this little brown bird called the white throated sparrow.
Although they seem like an average backyard bird, some of them are carrying a super gene that turns them into an angry bird.
The super gene is actually a chunk of one of their chromosomes that broke off and got reattached upside down.
I'm representing the standard unbroken version of this chromosome here in blue.
And next to it, the version that contains the super gene represented by the red section.
And my throated sparrows half the population has two copies of this standard blue chromosome.
And the other half has this combination of one standard and one super.
And when they have a copy of the super gene, they're more aggressive or angry than the ones that do not.
My research is pissed on one of the many genes inside of the super gene that is contributing to these sparrows becoming angry birds.
And it's called invasive active intestinal peptide or VIP VIP expression in a brain region called the anterior hypothalamus causes aggression and songbirds like the white throated sparrow.
Aggression and songbirds is displayed as singing, which is how they claim and defend their territory during the breeding season.
So the more VIP is expressed in this brain region, the more aggressively they will sing.
And if we compare the IP expression in the brain of us of an angry bird that has a super gene with the bird that does not we find more VIP the brain of the angry bird.
So I wanted to know if expression of the super gene specifically was what was leading to this higher level of VIP in the brain.
To do this, I measured VIP in sparrows brains in a way that allowed me to distinguish between the super gene version of VIP, the red squiggles and the standard of VIP, the blue squiggles.
And I found that the super gene version of the IP is expressed more than the standard version of the IP.
So one way that a gene can be expressed differently like this is a methylation, which is like a bump on the genetic code that changes the expression of a gene, but doesn't change the sequence itself.
And methylation usually suppresses gene expression, so the more a gene is expressed, the less it's methylated.
I'm working on measuring methylation of the whole VIP gene, but data from a small section suggests that the super gene is less methylated.
And that agrees with my finding that the super gene is expressed more.
So my research demonstrates that expression of super gene VIP in these angry birds is ramped up and that the reason for this might be lower methylation of the super gene.
And this increase of the IP and the brain may be contributing to these sparrows becoming angry birds.
My research and these findings help us understand how how a complex behavioral phenotype like aggression can be encoded in the genome.
And research like this broadens our knowledge of genetic basis of behavior helps us and services is stepping stone for future research on how behavior evolves.
And we still have a lot to learn, but thanks to this little brown bird, we now know a little bit more.
Raise your hand if you speak another language other than English.
So, according to the 2021 Census, nearly one in four Canadians are immigrants or permanent residents.
That means that almost 25% of Canada's population are foreign-born.
Although Canada celebrates individuals' diverse cultures and ethnicities,
people who immigrate to Canada may still experience acculturation.
Acculturation is a gradual process where one adapts to a new cultural environment
by adopting the values and traditions from the new host culture
while still maintaining some of the values and traditions from their heritage culture.
Now, first language loss, or L1 loss, is a documented phenomenon
that happens when individuals progressively loses their first language.
And this is especially common among those who relocate to a country
that speaks a foreign language that differs from their first language.
Research has shown that the loss of first language proficiencies has detrimental consequences
Therefore, my thesis aimed to look at prominent factors such as
acculturation that may be related to first language loss
that measure their English vocabulary size,
levels of acculturation to the host culture, and language dominance.
Participants also completed a one-on-one Zoom session
However, they did have higher English language proficiencies.
but lower English outcomes.
We also looked at whether residing in a multi-generational household
will help individuals preserve their first language.
and adopt the values and traditions from the host culture,
it's also critical to maintain one's first language and heritage culture as well.
Esther Li PhD in Developmental Psychology First language loss and maintenance in youth and adolescents with immigrant backgrounds Supervisor: Alexandra Gottardo
Pin ATL ee &. i Py in y language) proficiency f \ _ Acculturation | /N 4 Lower L1 (first _ Higher English proficiency Multigenerational home ~ Enculturation | Higher L1 proficiency Lower English proficiency
Do you remember the pandemic? Yeah, yeah, yeah. Well, in the interest of time, let me skip straight
to the answer. And the answer is yes, of course, we all remember how tough it was, but we have one
great weapon in our disposal against COVID. And that were the mRNA vaccines. You've been
probably hearing this word many, many times, mRNA. It is an incredible technology, but unfortunately,
it suffers from one major flaw. These vaccines always need to be kept in the cold, always in a
freezer, always in a fridge. And this is a massive issue in the developing world. Millions of doses
have been estimated to be wasted, chucked out in the bins, like leftover left on your table in the
the center of my screen. That one, ladies and gentlemen, is known as an encapsuline. And if
you're wondering what it is, well, simply put, an encapsuline is just a box, a container, something
that you can open up, put stuff on the inside, and that stuff stays there protected. And the reason
places on earth and also how tough they are. For all intents and purposes, an encapsuline,
this type of box is nigh indestructible. It's very, very hard to break them apart. So you probably see
where this is going. What if we were to combine the mRNA with its incredible potential as a vaccine,
with putting it inside such a strong container, something that could act as a safe to protect
this medicine, something that would allow us to create a new generation of vaccines that can be
shipped all over the world and provide protection to everybody, regardless of the conditions.
This is, and I'm not even joking, what my entire PhD is all about. In my first year, I focused on
making as many as these boxes as I could, like in a factory, bam, bam, bam. In my second and third
that it works. I'm happy to announce here with you that we have a working prototype of this,
a working prototype of this vaccine, that now we can move to the final stage, the stage of test,
asking questions like, is this going to be a tough vaccine, a vaccine that can survive all sorts of
conditions? Is this a vaccine that can be shipped all over the world for everybody? Is this vaccine
questions, and I know it's time is on the important matter here, but I'm pretty sure that the answer
is going to be yes. Thank you for your time.
faces become increasingly difficult.
Right now, doctors rely on very expensive brain scans and invasive tests that only provide
a brief snapshot of what's happening in your brain and body.
physiological signals.
heart rate activity using your smartwatch, and your walking pattern using video recordings.
Then, I train AI to act like a skilled detective that constantly spots clues and changes in
someone's daily movements, their speaking patterns, or even their typing speed.
It learns what normal looks like for each person so it can detect tiny shifts long before
they become noticeable symptoms.
I'm also exploring how these signals interact with each other to provide a richer picture
of the brain's communication network.
Usually they're perfectly synchronized.
stop playing altogether.
This early detection matters enormously because it means interventions like drugs and other
Okay now, let's finish with one more synchronized count.
Preserving What Matters Most, Before Memories Fade...
I decided to zero in on the lesser studied of the two, a protein called RUFO.
As we can see in the central green circle, I was successful in crystallizing RUFO, making
of my protein RUFO, the site of where the chemistry actually happens and compare it
to that of the first structure.
In a condition called supravalvular aortic stenosis, or SVAS, affecting 1 in every 10,000
cells of the aorta grow uncontrollably, thinking if we make the wall thicker, it will be strong
currently no cure for this condition.
I can convert those skin cells to a stem cell-like state.
in the not-too-distant future.
including cancer and even COVID-19, and directly test therapies on any organ system, in any
individual, including you and including me.
Induced Pluripotency Smooth Skin Cell Stem Cell Muscle Cell The Heart
Induced Pluripotency rn Smooth Skin Cell Stem Cell call The Heart
Induced Pluripotency The Aorta Smooth Skin Cell StemCell Muscle Cell |e The Heart
Induced Pluripotency a e J Smooth Skin Cell Stem Cell Muscle cell * The Heart
| Induced Pluripotency | Smooth i Muscle Call - |e@O Skin Cell Stem Cell The Heart
An 80,000-word thesis would take 9 hours to present. Each year, UCL hosts a competition where PhD students are required to present their research in just... 3 minutes.
How? What? Fire exit
ir =} Fire FS exit What?
Fire Fl am exit ay "7 What? Z is
Fire FA exit KS 4 What?
to monitor for COVID-19.
Since clinical testing has slowed down, wastewater testing has become one of our most reliable
tools to monitor COVID-19 disease trends, and some rural communities even prevented
outbreaks using this information.
The road to more equitable access to healthcare could start with something as simple as a
trip to the bathroom.
University 1 «Manitoba : ULTY OF GRADUATE STUDIES ‘UMANITOBA.CA/GRADUATE-STUDIES. How does Wastewater-Based Epidemiology Work? Disease marker shedding Sewage sample DNA/RNA extraction Measurement of DNA/RNA in urine and/or stool collection from the pathogen t
iniversity ULV GRADUATE STUDS UMANITOBA.CA/GRADUATE-STUDIES, How does Wastewater-Based Epidemiology Work? Disease marker shedding Sewage sample DNAVRNA extraction Measurement of DNA/RNA in urine and/or stool collection from the pathogen t
Hello everyone, I'm Willem and I'll be walking you through the setup of our latest NLP paper on tokenization and surrounding chromosomes.
First of all, what's tokenization and why do we need it?
There are many word types and languages, and most NLP models require to have a predefined vocabulary for which we have, for example, different embeddings.
If we took each word as a separate unit, then we would have a vocabulary size of maybe 1 million, which is problematic out of multiple reasons.
On the other hand, if we separated each word as a sequence of characters, then we would get very long sequences, and the semantic embeddings for each unit, that has characters, would be meaningless.
The solution is maybe somewhere in between, where we split words into some chunks.
The best tokenization is such that it maximizes the performance of some downstream NLP model.
So we can generate multiple tokenizations, then train a model on top of this tokenization, and take a look at the performance.
There is an issue with this. For example, in the context of machine translation, the tokenization takes just a few minutes, as well as the evaluation using automatic metrics.
Now the question becomes, how can we select the best tokenization without actually having to train the whole model?
The first option is to just use bifare encoding, but with vocabulary size of 32,000 tokens.
This will cover most application cases. However, if you are interested more in principled understanding of tokenization, you have to go deeper.
We can, for example, look at the token distribution and look at its tail, and look if there are any tokens that occur very infrequently.
If they do, we can say that this is not a good tokenization, because the models won't be able to learn the correct meaning of those low frequency tokens.
One way to look at it is that it's the one on the right, and the reason is that the token frequencies are more balanced.
In the paper we use more complex measures, such as efficiency and drainy entropy, which also tell us something more about the nature of tokenization.
Let's compare this predictive measure with the sequence length, that is, how many tokens on average are in the tokenized segments.
The y-axis is the performance, as measured by BLE, and the x-axis is the predictor.
In our paper, we develop proofs which justify and explain why drainy efficiency is a good predictor, and compare it to many others.
Also take a look at our other paper, which deals with specific tokenization approach, by Farrin Coding.
Which tokenization? - tokenization t - modelm - dataD t = argmax performance( m(t(D) ) Be
How do we know which tis good without training the whole model? = 7
How to choose t? 1) Choose BPE with V=32k
How to choose t? 1) Choose BPE with V=32k 2) Look at subword distribution induced by t Frequency
How to choose t? 3) Look at balance of distribution induced by t Tokenization A Tokenization B Frequency
How to choose t? 3) Lookat balance of distribution induced by t Tokenization A Tokenization B Frequency Entropy Rényi entropy H(p) =-> log, (p(x) H.(p) =1/(1-a) log, > p(x)* eff(p) = H(p) / log |V| eff,(p) = H,(p) / log |V|
Predicting Tokenization Quality Sequence length Pearson correlation 0.82 (p<0.001) Spearman correlation 0.65 (p<0.001) V=2k @ V=4k © V=8k = V 0.4 0.5 0.6 Rényi entropy efficiency with a = /
Recap Q: How do we know which t is good without training the whole model? A: By looking at how balanced the distribution is More in paper - Other characterizations of tokenization quality - Formal proof of Rényi efficiency bounds - Linking hypothesis of learnability and word frequency
disease schistosomiasis, which is what I study.
have the timer, the nutrient pollution that comes in there also causes these unexpected
They're not identical, so they may be a different size.
A not-so balanced host diet: Risk of freshwater parasite infection 2 o”* @
A not-so balanced host diet: Risk of freshwater parasite infection = 2 @& ~”@
Anot-so balanced host diet: Risk of freshwater parasite infection ie @ ®ee.:2 @ o”©@
A not-so balanced host diet: Risk of freshwater parasite infection az @ 2 « S °@ e >
A not-so balanced host diet: Risk of freshwater parasite infection a? @ se. & oe" ©@
Allow me to introduce you to this little brown bird called the white-throated sparrow.
that turns them into an angry bird.
reattached upside down.
I'm representing the standard unbroken version of this chromosome here in blue, and next
to it, the version that contains the super gene, represented by the red section.
For my throated sparrows, half the population has two copies of the standard blue chromosome,
When they have a copy of the super gene, they're more aggressive or angry than the ones that
My research is focused on one of the many genes inside of the super gene that is contributing
to these sparrows becoming angry birds, and it's called vasovactive intestinal peptide,
VIP expression in a brain region called the anterior hypothalamus causes aggression in
songbirds like the white-throated sparrow.
Aggression in songbirds is displayed as singing, which is how they claim and defend their territory
during the breeding season.
If we compare VIP expression in the brain of an angry bird that has a super gene with
a bird that does not, we find more VIP in the brain of the angry bird.
I wanted to know if expression of the super gene specifically was what was leading to
this higher level of VIP in the brain.
To do this, I measured VIP in sparrow brains in a way that allowed me to distinguish between
the super gene version of VIP, the red squiggles, and the standard of VIP, the blue
I found that the super gene version of VIP is expressed more than the standard version
One way that a gene can be expressed differently like this is methylation, which is like a
bump on the genetic code that changes the expression of a gene but doesn't change the
Methylation usually suppresses gene expression, so the more a gene is expressed, the less
suggests that the super gene is less methylated.
My research demonstrates that expression of super gene VIP in these angry birds is
ramped up and that the reason for this might be lower methylation of the super gene.
This increase of VIP in the brain may be contributing to these sparrows becoming angry birds.
can be encoded in the genome.
Research like this broadens our knowledge of the genetic basis of behavior and serves
as a stepping stone for future research on how behavior evolves.
