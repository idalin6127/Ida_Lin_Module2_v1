

--- Page 1 ---

2025 IEEE INTERNATIONAL WORKSHOP ON MACHINE LEARNING FOR SIGNAL PROCESSING, AUG. 31- SEP. 3, 2025, ISTANBUL, TURKEY
ENHANCED ARABIC TEXT RETRIEVAL WITH ATTENTIVE RELEVANCE SCORING
Salah Eddine Bekhouche! Azeddine Benlamoudi? Yazid Bounab?
Fadi Dornaika‘* Abdenour Hadid®°
University of the Basque Country UPV/EHU, San Sebastian, Spain
Lab. de Genie Electrique (LAGE), University of Ouargla, Ouargla, Algeria
3 Faculty of Pharmacy, Helsinki University, Helsinki, Finland

Va 4 IKERBASQUE, Basque Foundation for Science, Bilbao, Spain

N > Sorbonne University Abu Dhabi, Abu Dhabi, UAE

—_)

N

—

5 ABSTRACT in fewer dedicated resources and tools compared to other
~ Arabic poses a particular challenge for natural language ei hie dhe at tof trained transf dels ik
xa) processing (NLP) and information retrieval (IR) due to its Le te advent OF pre-trained’ transtormer Mocels lke

complex morphology, optional diacritics and the coexistence AraBERT, MARBERT, and multilingual BERT has signifi-
ml of Modern Standard Arabic (MSA) and various dialects. De- cantly advanced Arabic NLP, creating highly effective DPR
— spite the growing global significance of Arabic, it is still un- systems for Arabic requires more than just fine-tuning these
UO derrepresented in NLP research and benchmark resources. In general models on downstream tasks. Recognizing these lim-

Hh this paper, we present an enhanced Dense Passage Retrieval itations and the lack of dedicated Arabic DPR models, recent

YL, (DPR) framework developed specifically for Arabic. At the research, exemp lified by the develop ment of AraDPR [2], has
core of our approach is a novel Attentive Relevance Scoring focused on training specialized retrievers. AraDPR utilizes

rr (ARS) that replaces standard interaction mechanisms with AraBERT as Its backbone and employs a contrastive learning
> an adaptive scoring function that more effectively models approach, trained specifically ona combination of translated
ss the semantic relevance between questions and passages. Our benchmark datasets and native Arabic question-answering
+ method integrates pre-trained Arabic language models and datasets. This method has produced the first publicly avail-
oe) architectural refinements to improve retrieval performance able, contrastively trained Arabic DPR model, demonstrat-
N and significantly increase ranking accuracy when answering "8 state-of-the-art performance on Arabic passage retrieval
~ Arabic questions. The code is made publicly available at benchmarks and significantly outperforming both traditional
oO GitHub. methods and fine-tuned multilingual or cross-lingual models
Vay in Arabic open-domain QA contexts [2]. This was a crucial
N Index Terms— Arabic NLP, Dense Passage Retrieval, step towards building more robust and linguistically nuanced

S Attentive Relevance Scoring dense retrieval systems tailored specifically for the Arabic
ie language.

“a 1. INTRODUCTION However, even state-of-the-art dense retrieval models
fan} often rely on simple vector similarity measures (e.g., dot
Arabic, one of the most widely spoken languages globally, product or cosine similarity) for the final relevance scoring
presents unique linguistic challenges for natural language —_ between query and passage representations. These standard
processing (NLP) and information retrieval (IR). Applying scoring functions may not fully capture the intricate semantic
Dense Passage Retrieval (DPR) [!] to Arabic opens new relationships and account for the morphological variations in-
avenues but also introduces unique challenges. Its rich mor- _ herent in Arabic text. To address this limitation and enhance
phology, frequent use of diacritics, syntactic complexity, and —_ semantic matching capabilities, we present a novel system
the coexistence of Modern Standard Arabic (MSA) with di- incorporating Attentive Relevance Scoring (ARS). ARS re-
verse dialects pose significant difficulties for conventional places the typical final scoring step based on simple vector
retrieval systems, which often struggle with normalization similarity with a more adaptive and semantically aware scor-
and semantic understanding. Despite its global importance, _ing function designed to better model relevance in the context

Arabic remains underrepresented in NLP research, resulting — of Arabic’s linguistic features.
The supports of TotalEnergies and Sorbonne University Abu Dhabi are The potential applications for effective Arabic DPR are
fully acknowledged. vast, including enhanced question-answering systems, digital


--- Page 2 ---

libraries, Arabic-language search engines, and conversational for richer semantic matching while maintaining efficiency
agents for Arabic-speaking users. With the continuous in- — through pre-computation and optimized vector similarity
crease of annotated Arabic datasets and targeted research ef- search [10]. Other approaches like SPLADE [11] explore
forts, the effectiveness and usability of Arabic DPR systems __ learned sparse representations, bridging the gap between tra-
are expected to improve significantly. The main contributions ditional lexical matching and dense semantic retrieval, often
of this work are: offering competitive performance with better efficiency. Fur-
e We propose an enhanced dense retrieval framework thermore, model come ression techniques like Knowledge dis-
for Arabic, integrating lightweight transformer models tillation (¢.g., DistilBERT [1°], TinyBERT [15) are meneas-
. . : : ingly explored to create lightweight yet powerful retrieval
with an adaptive scoring mechanism. models suitable for resource-constrained environments.
¢ We introduce an ARS module to improve semantic
matching beyond conventional vector similarity func- Applying these advanced retrieval techniques to Ara-
tions used in standard DPR. bic poses unique challenges due to its complex morphology
(rich inflection and derivation), orthographic variations (e.g.,
* We present extensive experimental analysis, pointing — gptional diacritics, inconsistent spelling of certain letters),
out some limitations and future directions. and dialectal diversity [14]. Significant progress in Arabic
This rest of this paper is structured as follows: Section 2 NLP has been driven by the development of dedicated Ara-
overviews the foundational work on DPR in general and _ bic pre-trained language models, including AraBERT [15],
Arabic DPR in particular. In Section 3, we describe our MARBERT [16], ARBERT [16], AraELECTRA [17], and
methodology, highlighting the architectural advantages of the CamelBERT [18], which are trained on large Arabic cor-
ARS. Section 4 presents the experimental validation of our Pra and better capture the language’s nuances compared to
approach, providing detailed results and comparison against multilingual models. However, developing effective dense
some existing works. It also offers an in-depth analysis of the __‘Tettieval systems specifically for Arabic has lagged behind
findings, discussing their implications, limitations, and poten- English. Traditional Arabic IR systems often rely heavily on
tial future research directions. Finally, Section 5 summarizes | ™0rphological analysis and query expansion techniques to
our key findings and contributions to the field. handle lexical gaps [19]. The direct application of standard
DPR techniques, even when fine-tuning multilingual models,
2. RELATED WORK often yields suboptimal results due to the language’s specific
The field of IR has been significantly transformed by ad- characteristics Ph. Recognizing this ea, recent work has
vancements in deep learning, particularly the emergence of focused on creating dedicated Arabic dense retrieval models.
pre-trained transformer models [3, 4]. A key development A la ndmark contribution s AraDPR [2], the first publicly
stemming from this is DPR, which has become a corner- available, contrastively trained DPR model specifically for
stone for modem open-domain Question Answering (QA) Arabic. Utilizing AraBERT as its backbone and trained on a
and search systems. The core idea of DPR, popularized by mix of translated benchmarks and native Arabic QA datasets
[1], involves encoding both user queries and text passages (like ARCD Pop, AraDPR established a new state-of-the-
into low-dimensional, dense vector representations using art tor Arabic passage retrieval, significantly outperform.
dual-encoder architectures, typically based on BERT or its ing both traditional methods and general-purpose fine-tuned
variants. Relevance scoring is then performed by calculating models. ms nen lights ue mp Nevins er pnguase SP ecific
the similarity (e.g., dot product or cosine similarity) between training ane’ are Hectures tor ac teving MEN Penormanes i
the query vector and passage vectors. Retrieval is efficiently Arabic retrieval contexis, also emphasized by cross-lingual
. . . benchmark efforts like TyDi QA [21]. Despite the success
handled using Approximate Nearest Neighbor (ANN) search : .
algorithms over the pre-computed passage embeddings [5]. of models like AraDPR, standard dense retrieval P redom-
This paradigm demonstrated substantial improvements over inantly relies on a single vector representation for queries
traditional sparse retrieval methods like BM25 [6] on vari- an d Passages, with relevance de termined by simple geomet-
ous benchmarks. Subsequent research focused on refining ne similarity (dot p roduct/cosine). . While computationally
DPR, particularly through improved training strategies like efficient, this approach might oversImP lity the comp lex rel-
sophisticated negative sampling techniques (e.g., ANCE [7], evance judgments required, especially for morp hologically
RocketQA [8]) that dynamically mine hard negatives to create rich a nd semantically nuanced languages like Arabic. While
more robust models. While effective, standard DPR models late-interaction models like CoIBERT [9] address this by
based on large transformers can be computationally intensive. allowing token-level interactions, other neural ranking frame-
This has spurred research into more efficient architectures. works have long ©XP lored learned nferaction layers on ‘op
CoIBERT [9] introduced a late-interaction mechanism, cal- of global embeddings to imp rove upon simp le similarity
culating relevance based on fine-grained token-level interac- measures 2, 23]. Our work builds on this latter p aradigm,
tions between query and passage embeddings. This allows proposing a lightweight, adaptive Sconng module specifically
tailored for the challenges of Arabic retrieval.


--- Page 3 ---

Relevance Score and apply ¢2 normalization to obtain fixed-size embeddings:
q = Norm(£Q(q)icis}) € RB’, p = Norm(Ep(p)crsj) € R%,
Attentive Relevance (1)
Scoring where Norm(-) denotes ¢2 normalization. This normalization
Dense Dense projects vectors onto a unit hypersphere, which is beneficial
Question Passage eye: . soe : .
Representation Representation for stabilizing contrastive similarity computations.
Question Encoder Passage Encoder 3.2. Attentive Relevance Scoring
The ARS module computes an adaptive semantic similarity
Question Tokens Passage Tokens between query and passage embeddings through a trainable
interaction model.
UeCuha: Ua: First, the embeddings are projected into a shared space
using:
Question Passage hy _— W,4, h, _ Wp, (2)
uly sed ae fl ed Je al sie where Wy, W;, € IR” *¢ are learnable projection matrices and
ee i Ea h is the shared hidden dimensionality.
Next, we model interactions using element-wise multipli-
Fig. 1. Overview of the proposed APR framework. cation (©) followed by a non-linear activation to compute the
interaction vector a:
3. PROPOSED APPROACH a = tanh(h, © h,). (3)
This section introduces our proposed method, called Adaptive | Here, tanh(-) is the hyperbolic tangent function, which ap-
Passage Retrieval (APR), tailored for Arabic text retrieval. plies a non-linearity to the element-wise product of the pro-
Our approach builds upon the DPR framework [24] and jected embeddings.
incorporates a lightweight, Arabic-specific encoder (MiniB- Finally, a scalar relevance score r is computed via an at-
ERT) [25] alongside a novel scoring mechanism termed tention vector wa € R":
Attentive Relevance Scoring (ARS). This combination is de- +
signed to enhance retrieval accuracy by modeling enhanced r=a(w,a), (4)
semantic interactions in Arabic texts, while maintaining com- ; ; ; ;
putational efficiency suitable for low-resource settings. The where o(:) is the sigmoid function. .
overall architecture of our pro APR is illustrated in Figure 1. . During inference, the passage embeddings p (as defined
in Equation 1) are pre-computed for all Np documents in the
knowledge source to enable efficient query processing. When
3.1. Dual-Encoder Architecture anew query q arrives, its embedding is generated in real time.
The ARS module then computes a relevance score r) by in-
APR employs a dual-encoder architecture consisting of a __ttacting the query embedding with each of the pre-computed
question encoder (Eq) and a passage encoder (Ep), bothini- Passage embeddings p‘)j = 1,..., Np. Finally, all Np pas-
tialized with weights from MiniBERT, a transformer model _S@8¢S are ranked based on the resulting ARS scores r to
pre-trained on Arabic corpora. This initialization allows the Produce the retrieval output.
system to better capture Arabic linguistic features. Given
a question gq and a passage p, each encoder processes its 3.3. Loss Function
respective input independently, generating two types of rep- i . oo
resentations: sequence-level and pooled [CLS] token repre- To optimize both overall and fine-grained semantic alignment,
sentations. we define a total loss function:
The sequence-level representations, denoted H, € R?*4*¢4
and H, € R?**4 capture contextual embeddings for each Frota = 0 Leons + 8 « Layn + * Lrg: ()
token in the question and passage, respectively. Here, B is where a = 1, 8 = 1, and y = 0.1 are empirically de-
the batch size, L is the input lengths, and d is the hidden _ termined weights. During training, each batch contains B
dimension of the MiniBERT model. queries, with each query paired with one positive and a pool
For global semantic representation, we extract the final- of 29 negative passages, ensuring diverse negative exposure
layer hidden state corresponding to the special [CLS] token, _ while maintaining efficiency.


--- Page 4 ---

3.3.1. Contrastive Loss (Lons) While Lgyn encourages variance in the final ARS scores
; (r+ and r~), Lreg does the same for the raw logits (st and
We use a contrastive loss based on InfoNCE. It works on the s~). This helps maintain a useful range of values before ac-
[CLS] token embeddings. This loss helps the model align tivation, supports gradient flow, and prevents the model from
the query embedding (q@) with the correct p assage embedding becoming too confident or producing uniform predictions, es-
(p) and separate it from the incorrect ones (p™ ): pecially early in training or with hard negatives.
The regularization loss is:
B Tht _
Lcons = 4 S- log (ca ee an) 3 Lreg = Std (siren) + Std(Spatcn)+ (8)
Be \exp(ai pj? /7) + 05-1 exp(ai P;,;/7)
(6) Here, Shatch and Shatch ale the sets of raw, pre-sigmoid rel-
Here, B is the batch size. q; is the embedding for the evance scores (logits) for positive and negative examples in
i-th query. p; is the embedding for the correct (positive) pas- the batch. Std(-) means standard deviation.
sage. {Pi j yy are the embeddings for N negative passages
(N=29). The temperature parameter 7 > 0 is a learnable pa- 4. EXPERIMENTS
rameter used to scale the dot products.
4.1. Dataset
3.3.2. Dynamic Relevance Loss (Layn) For our experiments, we used the ArabicaQA dataset, a com-
Standard contrastive learning separates positive and negative prehensive, human-annotated Arabic question answering cor-
pairs, but it might not fully capture small differences in the — PUS specifically designed for open-domain retrieval and ma-
scores. This is especially important in Arabic, where similar Chine reading comprehension tasks. The dataset’ is divided
words can have slightly different meanings. To handle this, into standard training, validation and test subsets. The train-
we add a dynamic relevance loss that supervises the model’s _ 11 Set consists of 58,727 question-answer pairs, each accom-
relevance scores (ARS scores, 7). panied by a relevant positive passage with the answer and 29
This loss aims to increase the score r;* for the correct pas- hard negative passages. These hard negative passages are se-
sage and decrease the score r;_ for the incorrect one. At the mantically similar to the question, but do not contain the cor-
same time, it encourages a wider range of scores across the __Tect answer, which makes them valuable for training robust
batch. This prevents the scores from becoming too similar retrieval models. The validation set contains 12,722 question-
which can happen with difficult negative passages. answer pairs and the test set contains 12,597 question-answer.
The formulation for Layn, averaged over the batch of size The textual knowledge source for ArabicaQA is derived
B. is: from the Arabic Wikipedia’, which contains approximately
1,222,923 articles. These articles serve as the source passages
from which answers are retrieved or extracted. During per-
1 B i 7 formance evaluation on both the validation and test sets, each
Layn = — B S- [log(r; +) +log(l—r; + €)| (7) question is evaluated against the full Wikipedia split, ensur-
t=1 ing a realistic and comprehensive assessment of retrieval and
4 _ . reading comprehension capabilities.
Here, r;" and r; are the ARS scores (typically passed
through a sigmoid, and thus constrained between 0 and 1) for 4.2. Experimental Setup
the positive and negative passages, respectively. € is a small . . . .
constant (e.g., 10-8) added for numerical stability. The neg- All experiments were conducted on a machine with six
ative passage is randomly selected from the pool of negative NVIDIA L4 GPUs, each P roviding 24 GB of VRAM. A
passages. This loss aims to maximize r* and minimize ry, multi-GPU distributed training strategy was employed to ac-
ideally pushing r+ — 1 and r> 0 for each sample in celerate the training process. Mixed precision training was
the batch, ‘Thic a courages the ' rodel to produce confident not utilized, and the gradient accumulation step was set to |
and well-separated scores, improving the quality of passage to maintain stable gradient up dates. ;
retrieval. The model architecture comprises a question encoder and
a context (passage) encoder, each containing approximately
a 11.55 million parameters. An auxiliary ARS module intro-
3.3.3. Relevance Score Logit Regularization (Lyeg) duces an additional 0.13 million parameters, resulting in a to-
As an additional step, we apply a regularization loss on the tal of approximately 23.23 million trainable parameters for
raw relevance scores before applying the sigmoid function the complete APR model.
(called logits, s). This helps keep the training stable and pre- 1Qpen-ArabicaQA Human-Annotated Retriever Dataset
vents all outputs from becoming too similar. 2Open-ArabicaQA Wikipedia Split Dataset


--- Page 5 ---

Table 1. Retriever Module Performance Comparison (Top-k: +0.91% in Top-I, 44.17% m Top 10, and +1.53% in Top-100
accuracy. These consistent improvements demonstrate that
accuracy ontestset) 0 APR effectively leverages the ARS module to better distin-
Method Top-1  Top-10 Top-20 Top-50 Top-100 — guish truly relevant passages from semantically similar but
TF-IDF [27] 14.35 40.86 46.87 51.71 55.36 incorrect ones.
BM2S [6] 28.70 43.40 48.20 54.60 59.30 Furthermore, Figure 2 visually emphasizes the strong per-
DPR [1] 36.40 57.80 62.10 66.60 69.50 formance of APR at increasing values of k. While the perfor-
AraDPR [2] 36.10 58.40 63.40 68.60 71.90 mance gap between APR and the other retrievers is modest at
APR (Ours) 37.01 63.17 66.36 70.77 73.43 lower & values, it gradually increases as & increases, indicat-
ing superior ranking capabilities and a better understanding
of the relevance of answers within the large document collec-
Training was performed on the training split of the Arabi- tion. More specifically, the figure shows that APR achieves
caQA dataset, while model validation was conducted on the =, accuracy of about 38% at k = 5, which is slightly ahead of
validation split, consisting of 12,722 examples. Both training dense baseline methods such as AraDPR (36.10%) and DPR
and validation phases used a per-GPU batch size of 32. (36.40%), and significantly higher than sparse methods such
Optimization was carried out using the AdamW opti- ax BM25 (28.70%) and TF-IDF (14.35%). As k increases, all
mizer [26] with a fixed learning rate of 1 x 10~* and an ense models — including APR, AraDPR and DPR — begin
¢ value of 1 x 107°. A linear learning rate scheduler was tg plateau at k = 50, suggesting that most relevant passages
adopted, linearly increasing the learning rate from an initial = are found early in the ranking process. Despite this satura-
factor of 0.1 to the target value over the course of training. To tion, APR maintains a consistent lead over AraDPR and DPR
ensure numerical stability during training, gradient clipping at each k value, highlighting the benefits of response-based
was applied with a maximum norm of 1.0. ranking. Ultimately, APR achieves the highest top-k accu-
racy of 75.01% at k = 100, demonstrating its robustness even
4.3. Results and Discussion for broader retrieval scopes.
Figure 2 illustrates the top-k retrieval accuracy on the vali- These results highlight the strength of incorp orating An-
dation set, while Table | reports the performance on the test swer Relevance Scoring into dense retrieval. The higher Top-
set, comparing our results with state-of-the-art methods on k accuracy, particularly at low cutoffs such as Top “I and Top-
the ArabicaQA dataset. 10, ensures that downstream reader modules receive higher-
quality candidates, thereby improving the overall question an-
swering pipeline.
70 es ea ee ae a
=> oe gem ae aoe 5. CONCLUSION
Ey 60 pe opener oy
> tH] i a eee a se We presented an improved dense retrieval framework tailored
g 50 7 gavel WE eo ores ce for Arabic question answering. By integrating a lightweight
= fo encoder and ARS, our approach addresses key challenges in
hat 40 P: i =—® Proposed Arabic IR, including morphological complexity and limited
x He } —& AraDPR semantic generalization in traditional models. This work
=< 30 Pe i opens new directions for efficient and accurate retrieval in
a ; —f#- DPR underrepresented languages and lays the foundation for fu-
- 20 a —@ BM25 ture enhancements in Arabic-language AI systems. While
‘ ==) 1\F-IDF our results are promising, we recognize that we need a more
fe) 20 4O 60 80 100 detailed analysis. Future work will focus on doing thorough
k: # of Retrieved Passages ablation studies to separate the contributions of our proposed
components and conducting a qualitative analysis to provide
Fig. 2. Top-k retrieval accuracy comparison on the validation deeper insights into the model's practical strengths.
set of the ArabicaQA dataset. Our APR model demonstrates
consistent improvements across all values of k compared to 6. REFERENCES
existing methods. ({1] Vladimir Karpukhin, Barlas OSuz, Sewon Min, Patrick Lewis,
Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih,
As shown in Table 1, our proposed APR model outper- “Dense passage retrieval for open-domain question answer-
forms all baseline systems across all top-& retrieval thresh- ing.” in Proceedings of the 2020 Conference on Empirical
olds (k = 1,10, 20,50, 100). Compared to AraDPR—the Methods in Natural Language Processing (EMNLP). 2020, pp.
strongest Arabic baseline—APR achieves absolute gains of 6769-6781, Association for Computational Linguistics.


--- Page 6 ---

[2] Abdelrahman Abdallah, Mahmoud Kasem, Mahmoud Ab- [14] Ahmed Magdy Ezzeldin and Mohamed Shaheen, “A survey
dalla, Mohamed Mahmoud, Mohamed Elkasaby, Yasser El- of arabic question answering: challenges, tasks, approaches,
bendary, and Adam Jatowt, “Arabicaqa: A comprehensive tools, and future trends,” in Proceedings of The 13th inter-
dataset for arabic question answering,” in Proceedings of the national Arab conference on information technology (ACIT
47th International ACM SIGIR Conference on Research and 2012), 2012, pp. 1-8.

Development in Information Retrieval, 2024, pp. 2049-2059. [15] Wissam Antoun, Fady Baly, and Hazem Hajj, “Arabert:

[3] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Transformer-based model for arabic language understanding,”
Toutanova, “Bert: Pre-training of deep bidirectional transform- arXiv preprint arXiv:2003.00104, 2020.
ers for language understanding.” in Proceedings of the 2019 116) Muhammad Abdul-Mageed, AbdelRahim Elmadany, and
Conference of the North American Chapter of the Association El Moatez Billah Nagoudi “Arbert & marbert: Deep
for Computational Linguistics: Human Language Technolo- bidirectional transformers for arabic,” arXiv preprint
gies, Volume I (Long and Short Papers). 2019, pp. 4171-4186, arXiv:2101.01785. 2020.

Association for Computational Linguistics. . —
; : _. [17] Wissam Antoun, Fady Baly, and Hazem Hajj, “Araelectra: Pre-

[4] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko- training text discriminators for arabic language understand-
reit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Gy”? . . ye

? ? > > ing,” arXiv preprint arXiv:2012.15516, 2020.
Polosukhin, “Attention is all you need,’ Advances in neural . . .
. . oe ‘ [18] Go Inoue, Bashar Alhafni, Nurpeiis Baimukan, Houda
information processing systems, vol. 30, 2017. B aNj Habash. “The interpol f vant. si
ouamor, and Nizar Habash, e interplay of variant, size,

[5] Jeff Johnson, Matthijs Douze, and Hervé Jégou, “Billion-scale and task type in arabic pre-trained language models,” arXiv
Simanity ra wa Oe O Transactions on Big Data, preprint arXiv:2103.06678, 2021.
vol. 7, no. 3, pp. 535-547, . . . Ls .

oo [19] Kareem Darwish, Walid Magdy, et al., “Arabic information
[6] Stephen Roberson. Hugo Zaragoza, et al., “The probabilistic retrieval,” Foundations and Trends® in Information Retrieval,
relevance framework: Bm25 and beyond,’ Foundations and vol. 7. no. 4 239-342. 2014
. 7, no. 4, pp. , .
Trends® in Information Retrieval, vol. 3, no. 4, pp. 333-389, . .
2009. [20] Rasha Obeidat, Marwa Al-Harbi, Mahmoud Al-Ayyoub, and
: : . . Luay Alawneh, “Arquad: An expert-annotated arabic machine
7] ne xine renen wens: Ye Kwok ae uimny reading comprehension dataset,’ Cognitive Computation, vol.
in, and Paul Bennett, “Approximate nearest neighbor negative 16, no. 3, pp. 984-1003, 2024.
contrastive learning for dense text retrieval,” 2020. oo .
; : . ; . : _. : (21] Jonathan H Clark, Eunsol Choi, Michael Collins, Dan Garrette,

[8] Yingqi Qu, Yujing Ding, Jing Liu, Kai Liu, Rulyang Ren, Tom Kwiatkowski, Vitaly Nikolaev, and Jennimaria Palomaki,
Wayne Xin Zhao, Daxiang Dong, Hua Wu, and Haifeng Wang, “Tydi ga: A benchmark for inf oe : ‘ .
. ann ue Yydi qa: enchmark for information-seeking question an.

RocketQa: An optimized training approach to dense passage swering in ty pologically di verse languages,” Transactions of
ihe 2031 Confornee of the Nor th Anroving C / mM eof the the Association for Computational Linguistics, vol. 8, pp. 454—
of the onference of the North American Chapter of the 470, 2020.

Association for Computational Linguistics: Human Language 22) Po-Sen H Xiaod He. Jianf Gao. Li D Al
Technologies. 2021, pp. 5835-5847, Association for Computa- [22] Po-Sen Huang, Xiaodong He, ramen a0, 0 ENE, IEX

: Oo, Acero, and Larry Heck, “Learning deep structured semantic

tional Linguistics. dels f b h usi lickth h data” in P d
; a ; models for web search using clickthrough data,” in Proceed-

[9] om Khattab and wate fanenias hen Piicient and ef- ings of the 22nd ACM international conference on Information
ective passage search via contextualized late interaction over & Knowledge Management, 2013, pp. 2333-2338.
bert,’ in Proceedings of the 43rd International ACM SIGIR . . .

. . [23] Sparsh Gupta and Vitor R Carvalho, “Faq retrieval using atten-
conference on research and development in Information Re- . rn : .
. tive matching,” in Proceedings of the 42nd International ACM
trieval, 2020, pp. 39-48. .
[10] Keshav Santh 0 Khattab, Jon Saad-Fal Christ SIGIR Conference on Research and Development in Informa-
esnav santhanam, Omar attab, Jon Saad-Fralcon, r1Sto- tion Retrieval, 2019, pp. 929-932.
her Potts, and Matei Zaharia, “Colbertv2: Effecti d effi- . . . .
P . orre s an . are ana ° erie » ee we an “ (24] Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick SH
cient retrieval via lightweight late interaction,” arXiv preprint Lewis. Ledell Wu. S Ed Danai Ch aw.
arXiv:2112.01488, 2021. ewis, Ledell Wu, Sergey Edunov, Dangi Chen, an Ven-tau
Yih, “Dense passage retrieval for open-domain question an-
[11] Thibault Formal, Benjamin Piwowarski, and Stéphane Clin- swering.,” in EMNLP (1), 2020, pp. 6769-6781.
chant, “Splade: Sparse lexical and expansion model for first . . . i,
ye . . [25] Ali Safaya, Moutasem Abdullatif, and Deniz Yuret, “Kuisail
stage ranking,” in Proceedings of the 44th International ACM . :
. at semeval-2020 task 12: Bert-cnn for offensive speech iden-
SIGIR Conference on Research and Development in Informa- . on : _ : . .
. . tification in social media,” arXiv preprint arXiv:2007.13184,
tion Retrieval, 2021. 2020
[12] Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas 26) IL L hehil d Frank H. “D led weight d
Wolf, “Distilbert, a distilled version of bert: smaller, faster, [26] or Os © 1 ov aT Tan ; wh. one ° beanin hn.
cheaper and lighter,” arXiv preprint arXiv:1910.01108, 2019. regu vations (I CIR O18 onference on Learning Rep-
resentations , .

13] Xiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, . . .

[13] 1a0q! ta 0, Menu Pan MANNE ang m tang rao : on [27] Hussein Mozannar, Karl El Hajal, Elie Maamary, and Hazem
Linlin Li, Fang Wang, and Qun Liu, “Tinybert: Distill- gg : : gs . ;
. gs . . Hajj, “Neural arabic question answering,” arXiv preprint
ing bert for natural language understanding,” arXiv preprint .
arXiv:1909.10351. 2019 arXiv: 1906.05394, 2019.
